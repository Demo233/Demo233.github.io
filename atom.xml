<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>YIHAO&#39;S BLOG</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="yihao.ml/"/>
  <updated>2019-11-29T12:20:47.711Z</updated>
  <id>yihao.ml/</id>
  
  <author>
    <name>Yihao</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Anaconda IDEA</title>
    <link href="yihao.ml/2019/11/29/2019-11-29-test/"/>
    <id>yihao.ml/2019/11/29/2019-11-29-test/</id>
    <published>2019-11-29T12:20:47.711Z</published>
    <updated>2019-11-29T12:20:47.711Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>My new blog</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;My new blog&lt;/p&gt;&lt;!-- rebuild by neat --&gt;
      
    
    </summary>
    
      <category term="test" scheme="yihao.ml/categories/test/"/>
    
    
      <category term="test" scheme="yihao.ml/tags/test/"/>
    
  </entry>
  
  <entry>
    <title>Anaconda IDEA</title>
    <link href="yihao.ml/2019/11/11/2019%E2%80%9311-12-Anacoda%20IDEA/"/>
    <id>yihao.ml/2019/11/11/2019–11-12-Anacoda IDEA/</id>
    <published>2019-11-11T16:06:13.903Z</published>
    <updated>2019-11-29T12:20:47.711Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>好的优秀的IDEA可以提高生产效率，下面介绍一下Python的常用IDEA。</p><p>PyCharm：复杂大型的企业级应用。<br>IDLE、Sublime ： 300+行的代码程序。<br>Anaconda：适合科学计算和数据分析。</p><h3 id="概述"><a class="markdownIt-Anchor" href="#概述"></a> 概述</h3><p>Anacoda免费开源、支持8000个第三方库、包含多个主流工具，适合数据计算领域开发。下面了解一下里面的基本组件。</p><p>我们可以上www.continuum.io上安装最新的Anacoda IDEA。</p><p>它可以装在linux、win、mac上。实际上，Anacoda只是帮我们集成各类python工具，比如下面三个组件：</p><ul><li>Conda： 与pip和maven类似，是一个包管理工具用于管理第三方包。</li><li>Spyder： 它可以编写python代码，并且支持调试运行。</li><li>IPython： 是一个功能强大的交互式shell，编写代码变得更方便，适合进行交互式数据可视化和GUI相关应用开发，便于做数据分析。</li></ul><h3 id="conda"><a class="markdownIt-Anchor" href="#conda"></a> conda</h3><p>安装Anacoda ，打开Anacoda Navigator。在Environments一栏中可以看到默认的root环境空间，空间中已经包含了很多默认的第三方包。如果需要可以继续创建别的环境空间。</p><h3 id="spyder"><a class="markdownIt-Anchor" href="#spyder"></a> Spyder</h3><p>Spyder有三个工作区，分别为编辑区、文本导航和帮助区、IPython区</p><p>文本导航和帮助区我们不经常使用，建议删除掉简化开发页面。</p><p>在tools -&gt; perference -&gt; syntax coloring中可以设置主题</p><h3 id="ipython"><a class="markdownIt-Anchor" href="#ipython"></a> IPython</h3><p>In [num] : In指的是输入的命令，num是IPython的行号<br>Out [num] : Out指的是输出值或结果</p><p>下面介绍一下IPython中常用的两个指令：？和%</p><p>？跟在变量的后面，可以打印更多的详细信息。<br>%run <a href="http://file.py" target="_blank" rel="noopener">file.py</a> 可以运行任意目录下的file.py文件。</p><p>除上面命令以外，IPython还有很多其他指令，如下图所示：</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;好的优秀的IDEA可以提高生产效率，下面介绍一下Python的常用IDEA。&lt;/p&gt;&lt;p&gt;PyCharm：复杂
      
    
    </summary>
    
      <category term="机器学习" scheme="yihao.ml/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Anaconda" scheme="yihao.ml/tags/Anaconda/"/>
    
  </entry>
  
  <entry>
    <title>Flink基本概念（一）</title>
    <link href="yihao.ml/2019/11/11/2019%E2%80%9311-08-Flink%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    <id>yihao.ml/2019/11/11/2019–11-08-Flink基本概念/</id>
    <published>2019-11-11T05:31:46.485Z</published>
    <updated>2019-11-29T12:20:47.710Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>Flink是一个分布式、可拓展并行计算的流式计算引擎。大数据生态中，流式计算引擎还真不少，比如Spark、Storm；他们在处理数据时各有优缺点，那么Flink在流处理中，性能是不是要优于前两者，下面针对几个方面我们来快速的入个门。主要描述Flink中的基本概念。</p><h3 id="job-managers-task-managers-客户端clients"><a class="markdownIt-Anchor" href="#job-managers-task-managers-客户端clients"></a> Job Managers、Task Managers、客户端（Clients）</h3><p>下面简单说一说Flink中比较重要的三个组件，它们分别是JobManagers，TaskManagers，Client。</p><p><img src="https://i.loli.net/2019/11/11/BYN6pwKzoUgJEXk.png" alt="1AB09791-ABB6-4B9E-B8CF-5772F8D835BB.png"></p><h4 id="1什么是jobmanager"><a class="markdownIt-Anchor" href="#1什么是jobmanager"></a> 1.什么是JobManager？</h4><p>Job Managers，是整个应用的Master。它负责调度任务，协调checkpoint，协调故障恢复等。一个Job至少会有一个Job Manager。高可用部署下会有多个JobManagers，其中一个作为leader，其余的处于standby状态。</p><h4 id="2什么是taskmanagers"><a class="markdownIt-Anchor" href="#2什么是taskmanagers"></a> 2.什么是TaskManagers？</h4><p>TaskManagers，是整个应用的Workers。它主要执行dataflow中的tasks（更准确来说应该是subtasks），并且缓存和交换数据streams。每个job至少会有一个taskmanager。</p><h4 id="3什么是client"><a class="markdownIt-Anchor" href="#3什么是client"></a> 3.什么是client？</h4><p>client用户端主要负责提交DataFlow 到JobManager，取消或者更新Job。客户端的代码由Java或者Scala编写。运行代码指令如 flink run xxx.jar…</p><h4 id="4怎么启动jobmanagers和taskmanagers"><a class="markdownIt-Anchor" href="#4怎么启动jobmanagers和taskmanagers"></a> 4.怎么启动JobManagers和TaskManagers</h4><p>JobManagers和TaskManagers有多种启动方式：直接在机器上启动（standalone cluster）；在容器或资源管理框架中启动，比如Mesos、Yarn。后续我们会使用Yarn取启动JobManager</p><h3 id="task-和-subtasks"><a class="markdownIt-Anchor" href="#task-和-subtasks"></a> Task 和 SubTasks</h3><p>分布式计算中，Flink 将算子（operator）的 subtask 链接（chain）成 task。每个 task 由一个线程执行。把算子链接成 tasks 能够减少线程间切换和缓冲的开销，在降低延迟的同时提高了整体吞吐量。链接操作的配置详情可参考：<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/dev/stream/operators/#task-chaining-and-resource-groups" target="_blank" rel="noopener">chaining docs</a></p><p>下图的 dataflow 由五个 subtasks 执行，因此具有五个并行线程。</p><p><img src="https://i.loli.net/2019/11/11/gTNYUikXtphH9uz.png" alt="A290B58A-3250-43C5-848A-4865916DEB3E.png"></p><h3 id="task-slots和资源"><a class="markdownIt-Anchor" href="#task-slots和资源"></a> Task Slots和资源</h3><h4 id="1什么是slots槽"><a class="markdownIt-Anchor" href="#1什么是slots槽"></a> 1.什么是slots（槽）？</h4><p>flink中一个TaskManager中至少有一个slot（槽），每个Slot代表了TasManager的一份固定资源子集。subtasks实际运行在slot内，划分资源意味着subtask之间不会竞争资源，但是也意味着它们只拥有固定的资源。这里没有CPU的隔离，只是划分任务的内存资源。</p><p><img src="https://i.loli.net/2019/11/11/Fg9VWTZyKt6NEwk.png" alt="CE0C1C58-70EE-47AE-9135-7A8885527B86.png"></p><h4 id="2substasks怎么共享slot"><a class="markdownIt-Anchor" href="#2substasks怎么共享slot"></a> 2.substasks怎么共享slot</h4><p>在代码中可以使用slotSharingGroup（）函数来设置共享槽，如果不设置默认为default。</p><p>默认情况下，Flink 允许 subtasks 共享 slots，即使它们是不同 tasks 的 subtasks，只要它们来自同一个 job。因此，一个 slot 可能会负责这个 job 的整个管道（pipeline）。允许 slot sharing 有两个好处：</p><ul><li><p>Flink 集群需要与 job 中使用的最高并行度一样多的 slots。这样不需要计算作业总共包含多少个 tasks（具有不同并行度）。</p></li><li><p>更好的资源利用率。在没有 slot sharing 的情况下，简单的 subtasks（source/map()）将会占用和复杂的 subtasks （window）一样多的资源。通过 slot sharing，将示例中的并行度从 2 增加到 6 可以充分利用 slot 的资源，同时确保繁重的 subtask 在 TaskManagers 之间公平地获取资源。</p></li></ul><p><img src="https://i.loli.net/2019/11/11/g2wPquCrkO5exE1.png" alt="4B04802A-2045-468A-8085-B560661FD9C5.png"></p><p>参考资料:<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/concepts/runtime.html" target="_blank" rel="noopener">https://ci.apache.org/projects/flink/flink-docs-release-1.9/concepts/runtime.html</a></p><h3 id="后续总结"><a class="markdownIt-Anchor" href="#后续总结"></a> 后续总结</h3><ul><li>Flink 部署方式，重点Flink on yarn</li><li>如何向yarn申请Flink运行资源（JobManager）</li><li>如何提交一个简单的Flink程序</li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;Flink是一个分布式、可拓展并行计算的流式计算引擎。大数据生态中，流式计算引擎还真不少，比如Spark、St
      
    
    </summary>
    
      <category term="大数据" scheme="yihao.ml/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Flink" scheme="yihao.ml/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Kafka源码刨析之Produer Metadata更新机制（二）</title>
    <link href="yihao.ml/2019/11/07/2019-11-07-Kafka%E6%BA%90%E7%A0%81%E5%88%A8%E6%9E%90%E4%B9%8BProduer%20Metadata%E6%9B%B4%E6%96%B0%E6%9C%BA%E5%88%B6%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>yihao.ml/2019/11/07/2019-11-07-Kafka源码刨析之Produer Metadata更新机制（二）/</id>
    <published>2019-11-07T12:01:15.067Z</published>
    <updated>2019-11-29T12:20:47.710Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>在上一篇文章中，已经介绍了 Producer 的发送模型，Producer <code>dosend()</code> 方法中的第一步，就是获取相关的 topic 的 metadata，但在上篇中并没有深入展开，因为这部分的内容比较多，所以本文单独一篇文章进行介绍，本文主要来讲述以下三个问题：</p><pre><code>1. metadata 内容是什么；2. Producer 更新 metadata 的流程；3. Producer 在什么情况下会去更新 metadata；</code></pre><h3 id="metadata-内容"><a class="markdownIt-Anchor" href="#metadata-内容"></a> Metadata 内容</h3><p>Metadata 信息的内容可以通过源码看明白：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">// 这个类被 client 线程和后台 sender 所共享,它只保存了所有 topic 的部分数据,当我们请求一个它上面没有的 topic meta 时,它会通过发送 metadata update 来更新 meta 信息,</span><br><span class="line">// 如果 topic meta 过期策略是允许的,那么任何 topic 过期的话都会被从集合中移除,</span><br><span class="line">// 但是 consumer 是不允许 topic 过期的因为它明确地知道它需要管理哪些 topic</span><br><span class="line">public final class Metadata &#123;</span><br><span class="line">    private static final Logger log = LoggerFactory.getLogger(Metadata.class);</span><br><span class="line"></span><br><span class="line">    public static final long TOPIC_EXPIRY_MS = 5 * 60 * 1000;</span><br><span class="line">    private static final long TOPIC_EXPIRY_NEEDS_UPDATE = -1L;</span><br><span class="line"></span><br><span class="line">    private final long refreshBackoffMs; // metadata 更新失败时,为避免频繁更新 meta,最小的间隔时间,默认 100ms</span><br><span class="line">    private final long metadataExpireMs; // metadata 的过期时间, 默认 60,000ms</span><br><span class="line">    private int version; // 每更新成功1次，version自增1,主要是用于判断 metadata 是否更新</span><br><span class="line">    private long lastRefreshMs; // 最近一次更新时的时间（包含更新失败的情况）</span><br><span class="line">    private long lastSuccessfulRefreshMs; // 最近一次成功更新的时间（如果每次都成功的话，与前面的值相等, 否则，lastSuccessulRefreshMs &lt; lastRefreshMs)</span><br><span class="line">    private Cluster cluster; // 集群中一些 topic 的信息</span><br><span class="line">    private boolean needUpdate; // 是都需要更新 metadata</span><br><span class="line">    /* Topics with expiry time */</span><br><span class="line">    private final Map&lt;String, Long&gt; topics; // topic 与其过期时间的对应关系</span><br><span class="line">    private final List&lt;Listener&gt; listeners; // 事件监控者</span><br><span class="line">    private final ClusterResourceListeners clusterResourceListeners; //当接收到 metadata 更新时, ClusterResourceListeners的列表</span><br><span class="line">    private boolean needMetadataForAllTopics; // 是否强制更新所有的 metadata</span><br><span class="line">    private final boolean topicExpiryEnabled; // 默认为 true, Producer 会定时移除过期的 topic,consumer 则不会移除</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关于 topic 的详细信息（leader 所在节点、replica 所在节点、isr 列表）都是在<code>Cluster</code>实例中保存的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">// 并不是一个全集,metadata的主要组成部分</span><br><span class="line">public final class Cluster &#123;</span><br><span class="line"></span><br><span class="line">    // 从命名直接就看出了各个变量的用途</span><br><span class="line">    private final boolean isBootstrapConfigured;</span><br><span class="line">    private final List&lt;Node&gt; nodes; // node 列表</span><br><span class="line">    private final Set&lt;String&gt; unauthorizedTopics; // 未认证的 topic 列表</span><br><span class="line">    private final Set&lt;String&gt; internalTopics; // 内置的 topic 列表</span><br><span class="line">    private final Map&lt;TopicPartition, PartitionInfo&gt; partitionsByTopicPartition; // partition 的详细信息</span><br><span class="line">    private final Map&lt;String, List&lt;PartitionInfo&gt;&gt; partitionsByTopic; // topic 与 partition 的对应关系</span><br><span class="line">    private final Map&lt;String, List&lt;PartitionInfo&gt;&gt; availablePartitionsByTopic; //  可用（leader 不为 null）的 topic 与 partition 的对应关系</span><br><span class="line">    private final Map&lt;Integer, List&lt;PartitionInfo&gt;&gt; partitionsByNode; // node 与 partition 的对应关系</span><br><span class="line">    private final Map&lt;Integer, Node&gt; nodesById; // node 与 id 的对应关系</span><br><span class="line">    private final ClusterResource clusterResource;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// org.apache.kafka.common.PartitionInfo</span><br><span class="line">// topic-partition: 包含 topic、partition、leader、replicas、isr</span><br><span class="line">public class PartitionInfo &#123;</span><br><span class="line">    private final String topic;</span><br><span class="line">    private final int partition;</span><br><span class="line">    private final Node leader;</span><br><span class="line">    private final Node[] replicas;</span><br><span class="line">    private final Node[] inSyncReplicas;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Cluster 实例主要是保存：</p><pre><code>1. ``broker.id`` 与 ``node`` 的对应关系；2. topic 与 partition （``PartitionInfo``）的对应关系；3. node 与 partition （``PartitionInfo``）的对应关系。</code></pre><h3 id="producer-的-metadata-更新流程"><a class="markdownIt-Anchor" href="#producer-的-metadata-更新流程"></a> Producer 的 Metadata 更新流程</h3><p>Producer 在调用 <code>dosend()</code> 方法时，第一步就是通过 <code>waitOnMetadata</code> 方法获取该 topic 的 metadata 信息.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">// 等待 metadata 的更新</span><br><span class="line">private ClusterAndWaitTime waitOnMetadata(String topic, Integer partition, long maxWaitMs) throws InterruptedException &#123;</span><br><span class="line">    metadata.add(topic);// 在 metadata 中添加 topic 后,如果 metadata 中没有这个 topic 的 meta，那么 metadata 的更新标志设置为了 true</span><br><span class="line">    Cluster cluster = metadata.fetch();</span><br><span class="line">    Integer partitionsCount = cluster.partitionCountForTopic(topic);// 如果 topic 已经存在 meta 中,则返回该 topic 的 partition 数,否则返回 null</span><br><span class="line"></span><br><span class="line">    // 当前 metadata 中如果已经有这个 topic 的 meta 的话,就直接返回</span><br><span class="line">    if (partitionsCount != null &amp;&amp; (partition == null || partition &lt; partitionsCount))</span><br><span class="line">        return new ClusterAndWaitTime(cluster, 0);</span><br><span class="line"></span><br><span class="line">    long begin = time.milliseconds();</span><br><span class="line">    long remainingWaitMs = maxWaitMs;</span><br><span class="line">    long elapsed;</span><br><span class="line"></span><br><span class="line">    // 发送 metadata 请求,直到获取了这个 topic 的 metadata 或者请求超时</span><br><span class="line">    do &#123;</span><br><span class="line">        log.trace(&quot;Requesting metadata update for topic &#123;&#125;.&quot;, topic);</span><br><span class="line">        int version = metadata.requestUpdate();// 返回当前版本号,初始值为0,每次更新时会自增,并将 needUpdate 设置为 true</span><br><span class="line">        sender.wakeup();// 唤起 sender，发送 metadata 请求</span><br><span class="line">        try &#123;</span><br><span class="line">            metadata.awaitUpdate(version, remainingWaitMs);// 等待 metadata 的更新</span><br><span class="line">        &#125; catch (TimeoutException ex) &#123;</span><br><span class="line">            // Rethrow with original maxWaitMs to prevent logging exception with remainingWaitMs</span><br><span class="line">            throw new TimeoutException(&quot;Failed to update metadata after &quot; + maxWaitMs + &quot; ms.&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        cluster = metadata.fetch();</span><br><span class="line">        elapsed = time.milliseconds() - begin;</span><br><span class="line">        if (elapsed &gt;= maxWaitMs)</span><br><span class="line">            throw new TimeoutException(&quot;Failed to update metadata after &quot; + maxWaitMs + &quot; ms.&quot;);// 超时</span><br><span class="line">        if (cluster.unauthorizedTopics().contains(topic))// 认证失败，对当前 topic 没有 Write 权限</span><br><span class="line">            throw new TopicAuthorizationException(topic);</span><br><span class="line">        remainingWaitMs = maxWaitMs - elapsed;</span><br><span class="line">        partitionsCount = cluster.partitionCountForTopic(topic);</span><br><span class="line">    &#125; while (partitionsCount == null);// 不停循环,直到 partitionsCount 不为 null（即直到 metadata 中已经包含了这个 topic 的相关信息）</span><br><span class="line"></span><br><span class="line">    if (partition != null &amp;&amp; partition &gt;= partitionsCount) &#123;</span><br><span class="line">        throw new KafkaException(</span><br><span class="line">                String.format(&quot;Invalid partition given with record: %d is not in the range [0...%d).&quot;, partition, partitionsCount));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return new ClusterAndWaitTime(cluster, elapsed);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果 metadata 中不存在这个 topic 的 metadata，那么就请求更新 metadata，如果 metadata 没有更新的话，方法就一直处在 <code>do ... while</code> 的循环之中，在循环之中，主要做以下操作：</p><pre><code>1. ``metadata.requestUpdate()`` 将 metadata 的 ``needUpdate`` 变量设置为 true（强制更新），并返回当前的版本号（version），通过版本号来判断 metadata 是否完成更新；2. ``sender.wakeup()`` 唤醒 sender 线程，sender 线程又会去唤醒 NetworkClient 线程，NetworkClient 线程进行一些实际的操作（后面详细介绍）；3. ``metadata.awaitUpdate(version, remainingWaitMs)`` 等待 metadata 的更新。</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">// 更新 metadata 信息（根据当前 version 值来判断）</span><br><span class="line">public synchronized void awaitUpdate(final int lastVersion, final long maxWaitMs) throws InterruptedException &#123;</span><br><span class="line">    if (maxWaitMs &lt; 0) &#123;</span><br><span class="line">        throw new IllegalArgumentException(&quot;Max time to wait for metadata updates should not be &lt; 0 milli seconds&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    long begin = System.currentTimeMillis();</span><br><span class="line">    long remainingWaitMs = maxWaitMs;</span><br><span class="line">    while (this.version &lt;= lastVersion) &#123;// 不断循环,直到 metadata 更新成功,version 自增</span><br><span class="line">        if (remainingWaitMs != 0)</span><br><span class="line">            wait(remainingWaitMs);// 阻塞线程，等待 metadata 的更新</span><br><span class="line">        long elapsed = System.currentTimeMillis() - begin;</span><br><span class="line">        if (elapsed &gt;= maxWaitMs)// timeout</span><br><span class="line">            throw new TimeoutException(&quot;Failed to update metadata after &quot; + maxWaitMs + &quot; ms.&quot;);</span><br><span class="line">        remainingWaitMs = maxWaitMs - elapsed;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 <code>Metadata.awaitUpdate()</code> 方法中，线程会阻塞在 <code>while</code> 循环中，直到 metadata 更新成功或者 timeout。</p><p>从前面可以看出，此时 Producer 线程会阻塞在两个 <code>while</code> 循环中，直到 metadata 信息更新，那么 metadata 是如何更新的呢？如果有印象的话，前面应该已经介绍过了，主要是通过 <code>sender.wakeup()</code>来唤醒 sender 线程，间接唤醒 NetworkClient 线程，NetworkClient 线程来负责发送 Metadata 请求，并处理 Server 端的响应。</p><p>在 Kafka 源码分析之 Producer 发送模型（一） 中介绍 Producer 发送模型时，在第五步 <code>sender</code> 线程会调用 <code>NetworkClient.poll()</code> 方法进行实际的操作，其源码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">public List&lt;ClientResponse&gt; poll(long timeout, long now) &#123;</span><br><span class="line">        long metadataTimeout = metadataUpdater.maybeUpdate(now);// 判断是否需要更新 meta,如果需要就更新（请求更新 metadata 的地方）</span><br><span class="line">        try &#123;</span><br><span class="line">            this.selector.poll(Utils.min(timeout, metadataTimeout, requestTimeoutMs));</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            log.error(&quot;Unexpected error during I/O&quot;, e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // process completed actions</span><br><span class="line">        long updatedNow = this.time.milliseconds();</span><br><span class="line">        List&lt;ClientResponse&gt; responses = new ArrayList&lt;&gt;();</span><br><span class="line">        handleAbortedSends(responses);</span><br><span class="line">        handleCompletedSends(responses, updatedNow);// 通过 selector 中获取 Server 端的 response</span><br><span class="line">        handleCompletedReceives(responses, updatedNow);// 在返回的 handler 中，会处理 metadata 的更新</span><br><span class="line">        handleDisconnections(responses, updatedNow);</span><br><span class="line">        handleConnections();</span><br><span class="line">        handleInitiateApiVersionRequests(updatedNow);</span><br><span class="line">        handleTimedOutRequests(responses, updatedNow);</span><br><span class="line"></span><br><span class="line">        // invoke callbacks</span><br><span class="line">        for (ClientResponse response : responses) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                response.onComplete();</span><br><span class="line">            &#125; catch (Exception e) &#123;</span><br><span class="line">                log.error(&quot;Uncaught error in request completion:&quot;, e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return responses;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个方法中，主要会以下操作：</p><ul><li><code>metadataUpdater.maybeUpdate(now)</code>：判断是否需要更新 Metadata，如果需要更新的话，先与 Broker 建立连接，然后发送更新 metadata 的请求；</li><li>处理 Server 端的一些响应，这里主要讨论的是 <code>handleCompletedReceives(responses, updatedNow)</code> 方法，它会处理 Server 端返回的 Metadata 结果。</li></ul><p>先看一下 <code>metadataUpdater.maybeUpdate()</code> 的具体实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">public long maybeUpdate(long now) &#123;</span><br><span class="line">        // should we update our metadata?</span><br><span class="line">        // metadata 是否应该更新</span><br><span class="line">        long timeToNextMetadataUpdate = metadata.timeToNextUpdate(now);// metadata 下次更新的时间（需要判断是强制更新还是 metadata 过期更新,前者是立马更新,后者是计算 metadata 的过期时间）</span><br><span class="line">        // 如果一条 metadata 的 fetch 请求还未从 server 收到恢复,那么时间设置为 waitForMetadataFetch（默认30s）</span><br><span class="line">        long waitForMetadataFetch = this.metadataFetchInProgress ? requestTimeoutMs : 0;</span><br><span class="line"></span><br><span class="line">        long metadataTimeout = Math.max(timeToNextMetadataUpdate, waitForMetadataFetch);</span><br><span class="line">        if (metadataTimeout &gt; 0) &#123;// 时间未到时,直接返回下次应该更新的时间</span><br><span class="line">            return metadataTimeout;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Node node = leastLoadedNode(now);// 选择一个连接数最小的节点</span><br><span class="line">        if (node == null) &#123;</span><br><span class="line">            log.debug(&quot;Give up sending metadata request since no node is available&quot;);</span><br><span class="line">            return reconnectBackoffMs;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return maybeUpdate(now, node); // 可以发送 metadata 请求的话,就发送 metadata 请求</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * Add a metadata request to the list of sends if we can make one</span><br><span class="line">     */</span><br><span class="line">    // 判断是否可以发送请求,可以的话将 metadata 请求加入到发送列表中</span><br><span class="line">    private long maybeUpdate(long now, Node node) &#123;</span><br><span class="line">        String nodeConnectionId = node.idString();</span><br><span class="line"></span><br><span class="line">        if (canSendRequest(nodeConnectionId)) &#123;// 通道已经 ready 并且支持发送更多的请求</span><br><span class="line">            this.metadataFetchInProgress = true; // 准备开始发送数据,将 metadataFetchInProgress 置为 true</span><br><span class="line">            MetadataRequest.Builder metadataRequest; // 创建 metadata 请求</span><br><span class="line">            if (metadata.needMetadataForAllTopics())// 强制更新所有 topic 的 metadata（虽然默认不会更新所有 topic 的 metadata 信息，但是每个 Broker 会保存所有 topic 的 meta 信息）</span><br><span class="line">                metadataRequest = MetadataRequest.Builder.allTopics();</span><br><span class="line">            else // 只更新 metadata 中的 topics 列表（列表中的 topics 由 metadata.add() 得到）</span><br><span class="line">                metadataRequest = new MetadataRequest.Builder(new ArrayList&lt;&gt;(metadata.topics()));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            log.debug(&quot;Sending metadata request &#123;&#125; to node &#123;&#125;&quot;, metadataRequest, node.id());</span><br><span class="line">            sendInternalMetadataRequest(metadataRequest, nodeConnectionId, now);/ 发送 metadata 请求</span><br><span class="line">            return requestTimeoutMs;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // If there&apos;s any connection establishment underway, wait until it completes. This prevents</span><br><span class="line">        // the client from unnecessarily connecting to additional nodes while a previous connection</span><br><span class="line">        // attempt has not been completed.</span><br><span class="line">        if (isAnyNodeConnecting()) &#123;// 如果 client 正在与任何一个 node 的连接状态是 connecting,那么就进行等待</span><br><span class="line">            // Strictly the timeout we should return here is &quot;connect timeout&quot;, but as we don&apos;t</span><br><span class="line">            // have such application level configuration, using reconnect backoff instead.</span><br><span class="line">            return reconnectBackoffMs;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (connectionStates.canConnect(nodeConnectionId, now)) &#123;// 如果没有连接这个 node,那就初始化连接</span><br><span class="line">            // we don&apos;t have a connection to this node right now, make one</span><br><span class="line">            log.debug(&quot;Initialize connection to node &#123;&#125; for sending metadata request&quot;, node.id());</span><br><span class="line">            initiateConnect(node, now);// 初始化连接</span><br><span class="line">            return reconnectBackoffMs;</span><br><span class="line">        &#125;</span><br><span class="line">        return Long.MAX_VALUE;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"> // 发送 Metadata 请求   </span><br><span class="line"> private void sendInternalMetadataRequest(MetadataRequest.Builder builder,</span><br><span class="line">                                         String nodeConnectionId, long now) &#123;</span><br><span class="line">    ClientRequest clientRequest = newClientRequest(nodeConnectionId, builder, now, true);// 创建 metadata 请求</span><br><span class="line">    doSend(clientRequest, true, now);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以，每次 Producer 请求更新 metadata 时，会有以下几种情况：</p><pre><code>1. 如果 node 可以发送请求，则直接发送请求；2. 如果该 node 正在建立连接，则直接返回；3. 如果该 node 还没建立连接，则向 broker 初始化链接。</code></pre><p>而 KafkaProducer 线程之前是一直阻塞在两个 while 循环中，直到 metadata 更新</p><pre><code>1. sender 线程第一次调用 ``poll()`` 方法时，初始化与 node 的连接；2. sender 线程第二次调用 ``poll()`` 方法时，发送 ``Metadata`` 请求；3. sender 线程第三次调用 ``poll()`` 方法时，获取 ``metadataResponse``，并更新 metadata。</code></pre><p>经过上述 sender 线程三次调用 poll()方法，所请求的 metadata 信息才会得到更新，此时 Producer 线程也不会再阻塞，开始发送消息。</p><p><code>NetworkClient</code> 接收到 Server 端对 Metadata 请求的响应后，更新 Metadata 信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">// 处理任何已经完成的接收响应</span><br><span class="line">    private void handleCompletedReceives(List&lt;ClientResponse&gt; responses, long now) &#123;</span><br><span class="line">        for (NetworkReceive receive : this.selector.completedReceives()) &#123;</span><br><span class="line">            String source = receive.source();</span><br><span class="line">            InFlightRequest req = inFlightRequests.completeNext(source);</span><br><span class="line">            AbstractResponse body = parseResponse(receive.payload(), req.header);</span><br><span class="line">            log.trace(&quot;Completed receive from node &#123;&#125;, for key &#123;&#125;, received &#123;&#125;&quot;, req.destination, req.header.apiKey(), body);</span><br><span class="line">            if (req.isInternalRequest &amp;&amp; body instanceof MetadataResponse)// 如果是 meta 响应</span><br><span class="line">                metadataUpdater.handleCompletedMetadataResponse(req.header, now, (MetadataResponse) body);</span><br><span class="line">            else if (req.isInternalRequest &amp;&amp; body instanceof ApiVersionsResponse)</span><br><span class="line">                handleApiVersionsResponse(responses, req, now, (ApiVersionsResponse) body); // 如果是其他响应</span><br><span class="line">            else</span><br><span class="line">                responses.add(req.completed(body, now));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">        // 处理 Server 端对 Metadata 请求处理后的 response</span><br><span class="line">        public void handleCompletedMetadataResponse(RequestHeader requestHeader, long now, MetadataResponse response) &#123;</span><br><span class="line">            this.metadataFetchInProgress = false;</span><br><span class="line">            Cluster cluster = response.cluster();</span><br><span class="line">            // check if any topics metadata failed to get updated</span><br><span class="line">            Map&lt;String, Errors&gt; errors = response.errors();</span><br><span class="line">            if (!errors.isEmpty())</span><br><span class="line">                log.warn(&quot;Error while fetching metadata with correlation id &#123;&#125; : &#123;&#125;&quot;, requestHeader.correlationId(), errors);</span><br><span class="line"></span><br><span class="line">            // don&apos;t update the cluster if there are no valid nodes...the topic we want may still be in the process of being</span><br><span class="line">            // created which means we will get errors and no nodes until it exists</span><br><span class="line">            if (cluster.nodes().size() &gt; 0) &#123;</span><br><span class="line">                this.metadata.update(cluster, now);// 更新 meta 信息</span><br><span class="line">            &#125; else &#123;// 如果 metadata 中 node 信息无效,则不更新 metadata 信息</span><br><span class="line">                log.trace(&quot;Ignoring empty metadata response with correlation id &#123;&#125;.&quot;, requestHeader.correlationId());</span><br><span class="line">                this.metadata.failedUpdate(now);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>Producer Metadata 的更新策略</p><p>Metadata 会在下面两种情况下进行更新</p><pre><code>1. KafkaProducer 第一次发送消息时强制更新，其他时间周期性更新，它会通过 Metadata 的 lastRefreshMs, lastSuccessfulRefreshMs 这2个字段来实现；2. 强制更新： 调用 Metadata.requestUpdate() 将 needUpdate 置成了 true 来强制更新。</code></pre><p>在 NetworkClient 的 poll() 方法调用时，就会去检查这两种更新机制，只要达到其中一种，就行触发更新操作。</p><p>Metadata 的强制更新会在以下几种情况下进行：</p><pre><code>1. initConnect 方法调用时，初始化连接；2. ``poll()`` 方法中对 ``handleDisconnections()`` 方法调用来处理连接断开的情况，这时会触发强制更新；3. ``poll()`` 方法中对 ``handleTimedOutRequests()`` 来处理请求超时时；4. 发送消息时，如果无法找到 partition 的 leader；5. 处理 Producer 响应（handleProduceResponse），如果返回关于 Metadata 过期的异常，比如：没有 topic-partition 的相关 meta 或者 client 没有权限获取其 metadata。</code></pre><p>强制更新主要是用于处理各种异常情况。</p><p>转自：<a href="https://zhuanlan.zhihu.com/p/66190242" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/66190242</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;在上一篇文章中，已经介绍了 Producer 的发送模型，Producer &lt;code&gt;dosend()&lt;/c
      
    
    </summary>
    
      <category term="大数据" scheme="yihao.ml/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="kafka" scheme="yihao.ml/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka源码刨析之Produer发送模型（一）</title>
    <link href="yihao.ml/2019/11/07/2019%E2%80%9311-07-KafkaProducer%E6%BA%90%E7%A0%81%E5%88%A8%E6%9E%90/"/>
    <id>yihao.ml/2019/11/07/2019–11-07-KafkaProducer源码刨析/</id>
    <published>2019-11-07T12:01:15.066Z</published>
    <updated>2019-11-29T12:20:47.709Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>kafka是一个分布式的消息中间件，目前应用十分广泛。看源码不仅可以了解其底层的细节，同时，在看代码时，也能跟着大神们学到很多的编程技巧。</p><h3 id="kafkaproducer的使用"><a class="markdownIt-Anchor" href="#kafkaproducer的使用"></a> KafkaProducer的使用</h3><p>在Kafka中，Client端是由Java实现的，Server端是Scala实现的。下面我们从Client端开始，分析一下Kafaka中的Producer模型。开始之前我们先看一下怎么向Topic中生产数据。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line">import org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line">import org.apache.kafka.clients.producer.Producer;</span><br><span class="line"></span><br><span class="line">import java.util.Properties;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * Created by matt on 16/7/26.</span><br><span class="line"> */</span><br><span class="line">public class ProducerTest &#123;</span><br><span class="line">    private static String topicName;</span><br><span class="line">    private static int msgNum;</span><br><span class="line">    private static int key;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        props.put(&quot;bootstrap.servers&quot;, &quot;127.0.0.1:9092,127.0.0.2:9092&quot;);</span><br><span class="line">        props.put(&quot;key.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">        props.put(&quot;value.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">        topicName = &quot;test&quot;;</span><br><span class="line">        msgNum = 10; // 发送的消息数</span><br><span class="line"></span><br><span class="line">        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</span><br><span class="line">        for (int i = 0; i &lt; msgNum; i++) &#123;</span><br><span class="line">            String msg = i + &quot; This is matt&apos;s blog.&quot;;</span><br><span class="line">            producer.send(new ProducerRecord&lt;String, String&gt;(topicName, msg));</span><br><span class="line">        &#125;</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面可以看到如何向Topic中生产数据，Kafka在这方面封装的很好，只需要两步就可以完成操作：</p><pre><code>1. 初始化KafkaProducer类2. 调用send接口发送数据</code></pre><p>下面围绕着send接口开始展开。</p><h3 id="kafkaproducer中的send方法"><a class="markdownIt-Anchor" href="#kafkaproducer中的send方法"></a> KafkaProducer中的send方法</h3><p>用户使用producer.send发送数据，我们看一下send()的实现</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">// 异步向一个 topic 发送数据</span><br><span class="line">@Override</span><br><span class="line">public Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record) &#123;</span><br><span class="line">    return send(record, null);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 向 topic 异步地发送数据，当发送确认后唤起回调函数</span><br><span class="line">@Override</span><br><span class="line">public Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record, Callback callback) &#123;</span><br><span class="line">    // intercept the record, which can be potentially modified; this method does not throw exceptions</span><br><span class="line">    ProducerRecord&lt;K, V&gt; interceptedRecord = this.interceptors == null ? record : this.interceptors.onSend(record);</span><br><span class="line">    return doSend(interceptedRecord, callback);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接口最后会走一个doSend()方法，接着追进去</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">private Future&lt;RecordMetadata&gt; doSend(ProducerRecord&lt;K, V&gt; record, Callback callback) &#123;</span><br><span class="line">       TopicPartition tp = null;</span><br><span class="line">       try &#123;</span><br><span class="line">           // 1.确认数据要发送到的 topic 的 metadata 是可用的</span><br><span class="line">           ClusterAndWaitTime clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);</span><br><span class="line">           long remainingWaitMs = Math.max(0, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);</span><br><span class="line">           Cluster cluster = clusterAndWaitTime.cluster;</span><br><span class="line">           // 2.序列化 record 的 key 和 value</span><br><span class="line">           byte[] serializedKey;</span><br><span class="line">           try &#123;</span><br><span class="line">               serializedKey = keySerializer.serialize(record.topic(), record.key());</span><br><span class="line">           &#125; catch (ClassCastException cce) &#123;</span><br><span class="line">               throw new SerializationException(&quot;Can&apos;t convert key of class &quot; + record.key().getClass().getName() +</span><br><span class="line">                       &quot; to class &quot; + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                       &quot; specified in key.serializer&quot;);</span><br><span class="line">           &#125;</span><br><span class="line">           byte[] serializedValue;</span><br><span class="line">           try &#123;</span><br><span class="line">               serializedValue = valueSerializer.serialize(record.topic(), record.value());</span><br><span class="line">           &#125; catch (ClassCastException cce) &#123;</span><br><span class="line">               throw new SerializationException(&quot;Can&apos;t convert value of class &quot; + record.value().getClass().getName() +</span><br><span class="line">                       &quot; to class &quot; + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                       &quot; specified in value.serializer&quot;);</span><br><span class="line">           &#125;</span><br><span class="line"></span><br><span class="line">           // 3. 获取该 record 的 partition 的值（可以指定,也可以根据算法计算）</span><br><span class="line">           int partition = partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">           int serializedSize = Records.LOG_OVERHEAD + Record.recordSize(serializedKey, serializedValue);</span><br><span class="line">           ensureValidRecordSize(serializedSize); // record 的字节超出限制或大于内存限制时,就会抛出 RecordTooLargeException 异常</span><br><span class="line">           tp = new TopicPartition(record.topic(), partition);</span><br><span class="line">           long timestamp = record.timestamp() == null ? time.milliseconds() : record.timestamp(); // 时间戳</span><br><span class="line">           log.trace(&quot;Sending record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;&quot;, record, callback, record.topic(), partition);</span><br><span class="line">           Callback interceptCallback = this.interceptors == null ? callback : new InterceptorCallback&lt;&gt;(callback, this.interceptors, tp);</span><br><span class="line">           // 4. 向 accumulator 中追加数据</span><br><span class="line">           RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue,interceptCallback, remainingWaitMs);</span><br><span class="line">           // 5. 如果 batch 已经满了,唤醒 sender 线程发送数据</span><br><span class="line">           if (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">               log.trace(&quot;Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch&quot;,record.topic(),partition);</span><br><span class="line">               this.sender.wakeup();</span><br><span class="line">           &#125;</span><br><span class="line">           return result.future;</span><br><span class="line">       &#125; catch (ApiException e) &#123;</span><br><span class="line">           log.debug(&quot;Exception occurred during message send:&quot;, e);</span><br><span class="line">           if (callback != null)</span><br><span class="line">               callback.onCompletion(null, e);</span><br><span class="line">           this.errors.record();</span><br><span class="line">           if (this.interceptors != null)</span><br><span class="line">               this.interceptors.onSendError(record, tp, e);</span><br><span class="line">           return new FutureFailure(e);</span><br><span class="line">       &#125; catch (InterruptedException e) &#123;</span><br><span class="line">           this.errors.record();</span><br><span class="line">           if (this.i nterceptors != null)</span><br><span class="line">               this.interceptors.onSendError(record, tp, e);</span><br><span class="line">           throw new InterruptException(e);</span><br><span class="line">       &#125; catch (BufferExhaustedException e) &#123;</span><br><span class="line">           this.errors.record();</span><br><span class="line">           this.metrics.sensor(&quot;buffer-exhausted-records&quot;).record();</span><br><span class="line">           if (this.interceptors != null)</span><br><span class="line">               this.interceptors.onSendError(record, tp, e);</span><br><span class="line">           throw e;</span><br><span class="line">       &#125; catch (KafkaException e) &#123;</span><br><span class="line">           this.errors.record();</span><br><span class="line">           if (this.interceptors != null)</span><br><span class="line">               this.interceptors.onSendError(record, tp, e);</span><br><span class="line">           throw e;</span><br><span class="line">       &#125; catch (Exception e) &#123;</span><br><span class="line">           if (this.interceptors != null)</span><br><span class="line">               this.interceptors.onSendError(record, tp, e);</span><br><span class="line">           throw e;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 dosend() 方法的实现上，一条 Record 数据的发送，可以分为以下五步：</p><pre><code>1. 确认数据要发送到的 topic 的 metadata 是可用的（如果该 partition 的 leader 存在则是可用的，如果开启权限时，client 有相应的权限），如果没有 topic 的 metadata 信息，就需要获取相应的 metadata；2. 序列化 record 的 key 和 value；3. 获取该 record 要发送到的 partition（可以指定，也可以根据算法计算）；4. 向 accumulator 中追加 record 数据，数据会先进行缓存；5. 如果追加完数据后，对应的 RecordBatch 已经达到了 batch.size 的大小（或者batch 的剩余空间不足以添加下一条 Record），则唤醒 sender 线程发送数据。</code></pre><p>数据的发送过程，可以简单总结为以上五点，下面会这几部分的具体实现进行详细分析。</p><h2 id="发送的过程详解"><a class="markdownIt-Anchor" href="#发送的过程详解"></a> 发送的过程详解</h2><h3 id="获取-topic-的-metadata-信息"><a class="markdownIt-Anchor" href="#获取-topic-的-metadata-信息"></a> 获取 topic 的 metadata 信息</h3><p>Producer 通过 waitOnMetadata() 方法来获取对应 topic 的 metadata 信息，这部分后面会单独抽出一篇文章来介绍，这里就不再详述，总结起来就是：在数据发送前，需要先该 topic 是可用的。</p><h3 id="key-和-value-的序列化"><a class="markdownIt-Anchor" href="#key-和-value-的序列化"></a> key 和 value 的序列化</h3><p>Producer 端对 record 的 key 和 value 值进行序列化操作，在 Consumer 端再进行相应的反序列化，Kafka 内部提供的序列化和反序列化算法如下图所示：</p><p><img src="https://i.loli.net/2019/11/07/r4CtIEAcmhwN7xo.jpg" alt="D8B532DC-1C96-4778-875F-2466E5835EFA.jpeg"><br>Need support? Please accept cookies and refresh the page 😃</p><p>Kafka serialize &amp; deserialize</p><p>当然我们也是可以自定义序列化的具体实现，不过一般情况下，Kafka 内部提供的这些方法已经足够使用。</p><h3 id="获取-partition-值"><a class="markdownIt-Anchor" href="#获取-partition-值"></a> 获取 partition 值</h3><p>关于 partition 值的计算，分为三种情况：</p><p>指明 partition 的情况下，直接将指明的值直接作为 partiton 值；<br>没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值；<br>既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。<br>具体实现如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 当 record 中有 partition 值时，直接返回，没有的情况下调用 partitioner 的类的 partition 方法去计算（KafkaProducer.class）</span><br><span class="line">private int partition(ProducerRecord&lt;K, V&gt; record, byte[] serializedKey, byte[] serializedValue, Cluster cluster) &#123;</span><br><span class="line">    Integer partition = record.partition();</span><br><span class="line">    return partition != null ?</span><br><span class="line">            partition :</span><br><span class="line">            partitioner.partition(</span><br><span class="line">                    record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Producer 默认使用的<code>partitioner</code>是<code>org.apache.kafka.clients.producer.internals.DefaultPartitioner</code>，用户也可以自定义 partition 的策略，下面是这个类两个方法的具体实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) &#123;</span><br><span class="line">        List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">        int numPartitions = partitions.size();</span><br><span class="line">        if (keyBytes == null) &#123;// 没有指定 key 的情况下</span><br><span class="line">            int nextValue = nextValue(topic); // 第一次的时候产生一个随机整数,后面每次调用在之前的基础上自增;</span><br><span class="line">            List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">            // leader 不为 null,即为可用的 partition</span><br><span class="line">            if (availablePartitions.size() &gt; 0) &#123;</span><br><span class="line">                int part = Utils.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">                return availablePartitions.get(part).partition();</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                return Utils.toPositive(nextValue) % numPartitions;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123;// 有 key 的情况下,使用 key 的 hash 值进行计算</span><br><span class="line">            return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions; // 选择 key 的 hash 值</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 根据 topic 获取对应的整数变量</span><br><span class="line">    private int nextValue(String topic) &#123;</span><br><span class="line">        AtomicInteger counter = topicCounterMap.get(topic);</span><br><span class="line">        if (null == counter) &#123; // 第一次调用时，随机产生</span><br><span class="line">            counter = new AtomicInteger(new Random().nextInt());</span><br><span class="line">            AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);</span><br><span class="line">            if (currentCounter != null) &#123;</span><br><span class="line">                counter = currentCounter;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return counter.getAndIncrement(); // 后面再调用时，根据之前的结果自增</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这就是 Producer 中默认的 partitioner 实现。</p><h3 id="向-accumulator-写数据"><a class="markdownIt-Anchor" href="#向-accumulator-写数据"></a> 向 accumulator 写数据</h3><p>Producer 会先将 record 写入到 buffer 中，当达到一个 batch.size 的大小时，再唤起 sender 线程去发送 RecordBatch（第五步），这里先详细分析一下 Producer 是如何向 buffer 中写入数据的。</p><p>Producer 是通过 RecordAccumulator 实例追加数据，RecordAccumulator 模型如下图所示，一个重要的变量就是 ConcurrentMap&lt;TopicPartition, Deque<recordbatch>&gt; batches，每个 TopicPartition 都会对应一个 Deque<recordbatch>，当添加数据时，会向其 topic-partition 对应的这个 queue 最新创建的一个 RecordBatch 中添加 record，而发送数据时，则会先从 queue 中最老的那个 RecordBatch 开始发送。</recordbatch></recordbatch></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![C89D1394-08D6-416D-814D-BC19D65091B2.jpeg](https://i.loli.net/2019/11/07/C6bS5ieDGfnAOsg.jpg)</span><br></pre></td></tr></table></figure><p>Producer RecordAccumulator 模型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">// org.apache.kafka.clients.producer.internals.RecordAccumulator</span><br><span class="line">     // 向 accumulator 添加一条 record，并返回添加后的结果（结果主要包含: future metadata、batch 是否满的标志以及新 batch 是否创建）其中， maxTimeToBlock 是 buffer.memory 的 block 的最大时间</span><br><span class="line">    public RecordAppendResult append(TopicPartition tp,</span><br><span class="line">                                     long timestamp,</span><br><span class="line">                                     byte[] key,</span><br><span class="line">                                     byte[] value,</span><br><span class="line">                                     Callback callback,</span><br><span class="line">                                     long maxTimeToBlock) throws InterruptedException &#123;</span><br><span class="line">        appendsInProgress.incrementAndGet();</span><br><span class="line">        try &#123;</span><br><span class="line">            Deque&lt;RecordBatch&gt; dq = getOrCreateDeque(tp);// 每个 topicPartition 对应一个 queue</span><br><span class="line">            synchronized (dq) &#123;// 在对一个 queue 进行操作时,会保证线程安全</span><br><span class="line">                if (closed)</span><br><span class="line">                    throw new IllegalStateException(&quot;Cannot send after the producer is closed.&quot;);</span><br><span class="line">                RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq); // 追加数据</span><br><span class="line">                if (appendResult != null)// 这个 topic-partition 已经有记录了</span><br><span class="line">                    return appendResult;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            // 为 topic-partition 创建一个新的 RecordBatch, 需要初始化相应的 RecordBatch，要为其分配的大小是: max（batch.size, 加上头文件的本条消息的大小）</span><br><span class="line">            int size = Math.max(this.batchSize, Records.LOG_OVERHEAD + Record.recordSize(key, value));</span><br><span class="line">            log.trace(&quot;Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125;&quot;, size, tp.topic(), tp.partition());</span><br><span class="line">            ByteBuffer buffer = free.allocate(size, maxTimeToBlock);// 给这个 RecordBatch 初始化一个 buffer</span><br><span class="line">            synchronized (dq) &#123;</span><br><span class="line">                if (closed)</span><br><span class="line">                    throw new IllegalStateException(&quot;Cannot send after the producer is closed.&quot;);</span><br><span class="line"></span><br><span class="line">                RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);</span><br><span class="line">                if (appendResult != null) &#123;// 如果突然发现这个 queue 已经存在，那么就释放这个已经分配的空间</span><br><span class="line">                    free.deallocate(buffer);</span><br><span class="line">                    return appendResult;</span><br><span class="line">                &#125;</span><br><span class="line">                // 给 topic-partition 创建一个 RecordBatch</span><br><span class="line">                MemoryRecordsBuilder recordsBuilder = MemoryRecords.builder(buffer, compression, TimestampType.CREATE_TIME, this.batchSize);</span><br><span class="line">                RecordBatch batch = new RecordBatch(tp, recordsBuilder, time.milliseconds());</span><br><span class="line">                // 向新的 RecordBatch 中追加数据</span><br><span class="line">                FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, callback, time.milliseconds()));</span><br><span class="line"></span><br><span class="line">                dq.addLast(batch);// 将 RecordBatch 添加到对应的 queue 中</span><br><span class="line">                incomplete.add(batch);// 向未 ack 的 batch 集合添加这个 batch</span><br><span class="line">                // 如果 dp.size()&gt;1 就证明这个 queue 有一个 batch 是可以发送了</span><br><span class="line">                return new RecordAppendResult(future, dq.size() &gt; 1 || batch.isFull(), true);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            appendsInProgress.decrementAndGet();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>总结一下其 record 写入的具体流程如下图所示：</p><p><img src="https://i.loli.net/2019/11/07/bL3CzBcH7G1f2Pe.jpg" alt="2EC40DD6-2B51-4F00-B2C7-CB6242E47B8F.jpeg"></p><p>Producer RecordAccumulator record 写入流程</p><p>获取该 topic-partition 对应的 queue，没有的话会创建一个空的 queue；<br>向 queue 中追加数据，先获取 queue 中最新加入的那个 RecordBatch，如果不存在或者存在但剩余空余不足以添加本条 record 则返回 null，成功写入的话直接返回结果，写入成功；<br>创建一个新的 RecordBatch，初始化内存大小根据 max(batch.size, Records.LOG_OVERHEAD + Record.recordSize(key, value)) 来确定（防止单条 record 过大的情况）；<br>向新建的 RecordBatch 写入 record，并将 RecordBatch 添加到 queue 中，返回结果，写入成功。</p><h3 id="发送-recordbatch"><a class="markdownIt-Anchor" href="#发送-recordbatch"></a> 发送 RecordBatch</h3><p>当 record 写入成功后，如果发现 RecordBatch 已满足发送的条件（通常是 queue 中有多个 batch，那么最先添加的那些 batch 肯定是可以发送了），那么就会唤醒 sender 线程，发送 RecordBatch。</p><p>sender 线程对 RecordBatch 的处理是在 run() 方法中进行的，该方法具体实现如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">void run(long now) &#123;</span><br><span class="line">        Cluster cluster = metadata.fetch();</span><br><span class="line">        // 获取那些已经可以发送的 RecordBatch 对应的 nodes</span><br><span class="line">        RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(cluster, now);</span><br><span class="line"></span><br><span class="line">        // 如果有 topic-partition 的 leader 是未知的,就强制 metadata 更新</span><br><span class="line">        if (!result.unknownLeaderTopics.isEmpty()) &#123;</span><br><span class="line">            for (String topic : result.unknownLeaderTopics)</span><br><span class="line">                this.metadata.add(topic);</span><br><span class="line">            this.metadata.requestUpdate();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 如果与node 没有连接（如果可以连接,同时初始化该连接）,就证明该 node 暂时不能发送数据,暂时移除该 node</span><br><span class="line">        Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</span><br><span class="line">        long notReadyTimeout = Long.MAX_VALUE;</span><br><span class="line">        while (iter.hasNext()) &#123;</span><br><span class="line">            Node node = iter.next();</span><br><span class="line">            if (!this.client.ready(node, now)) &#123;</span><br><span class="line">                iter.remove();</span><br><span class="line">                notReadyTimeout = Math.min(notReadyTimeout, this.client.connectionDelay(node, now));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 返回该 node 对应的所有可以发送的 RecordBatch 组成的 batches（key 是 node.id）,并将 RecordBatch 从对应的 queue 中移除</span><br><span class="line">        Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = this.accumulator.drain(cluster, result.readyNodes, this.maxRequestSize, now);</span><br><span class="line">        if (guaranteeMessageOrder) &#123;</span><br><span class="line">            //记录将要发送的 RecordBatch</span><br><span class="line">            for (List&lt;RecordBatch&gt; batchList : batches.values()) &#123;</span><br><span class="line">                for (RecordBatch batch : batchList)</span><br><span class="line">                    this.accumulator.mutePartition(batch.topicPartition);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 将由于元数据不可用而导致发送超时的 RecordBatch 移除</span><br><span class="line">        List&lt;RecordBatch&gt; expiredBatches = this.accumulator.abortExpiredBatches(this.requestTimeout, now);</span><br><span class="line">        for (RecordBatch expiredBatch : expiredBatches)</span><br><span class="line">            this.sensors.recordErrors(expiredBatch.topicPartition.topic(), expiredBatch.recordCount);</span><br><span class="line"></span><br><span class="line">        sensors.updateProduceRequestMetrics(batches);</span><br><span class="line"></span><br><span class="line">        long pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);</span><br><span class="line">        if (!result.readyNodes.isEmpty()) &#123;</span><br><span class="line">            log.trace(&quot;Nodes with data ready to send: &#123;&#125;&quot;, result.readyNodes);</span><br><span class="line">            pollTimeout = 0;</span><br><span class="line">        &#125;</span><br><span class="line">        // 发送 RecordBatch</span><br><span class="line">        sendProduceRequests(batches, now);</span><br><span class="line"></span><br><span class="line">        this.client.poll(pollTimeout, now); // 关于 socket 的一些实际的读写操作（其中包括 meta 信息的更新）</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这段代码前面有很多是其他的逻辑处理，如：移除暂时不可用的 node、处理由于元数据不可用导致的超时RecordBatch，真正进行发送发送RecordBatch的是sendProduceRequests(batches, now)这个方法，具体是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Transfer the record batches into a list of produce requests on a per-node basis</span><br><span class="line"> */</span><br><span class="line">private void sendProduceRequests(Map&lt;Integer, List&lt;RecordBatch&gt;&gt; collated, long now) &#123;</span><br><span class="line">    for (Map.Entry&lt;Integer, List&lt;RecordBatch&gt;&gt; entry : collated.entrySet())</span><br><span class="line">        sendProduceRequest(now, entry.getKey(), acks, requestTimeout, entry.getValue());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * Create a produce request from the given record batches</span><br><span class="line"> */</span><br><span class="line">// 发送 produce 请求</span><br><span class="line">private void sendProduceRequest(long now, int destination, short acks, int timeout, List&lt;RecordBatch&gt; batches) &#123;</span><br><span class="line">    Map&lt;TopicPartition, MemoryRecords&gt; produceRecordsByPartition = new HashMap&lt;&gt;(batches.size());</span><br><span class="line">    final Map&lt;TopicPartition, RecordBatch&gt; recordsByPartition = new HashMap&lt;&gt;(batches.size());</span><br><span class="line">    for (RecordBatch batch : batches) &#123;</span><br><span class="line">        TopicPartition tp = batch.topicPartition;</span><br><span class="line">        produceRecordsByPartition.put(tp, batch.records());</span><br><span class="line">        recordsByPartition.put(tp, batch);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ProduceRequest.Builder requestBuilder =</span><br><span class="line">            new ProduceRequest.Builder(acks, timeout, produceRecordsByPartition);</span><br><span class="line">    RequestCompletionHandler callback = new RequestCompletionHandler() &#123;</span><br><span class="line">        public void onComplete(ClientResponse response) &#123;</span><br><span class="line">            handleProduceResponse(response, recordsByPartition, time.milliseconds());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    String nodeId = Integer.toString(destination);</span><br><span class="line">    ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != 0, callback);</span><br><span class="line">    client.send(clientRequest, now);</span><br><span class="line">    log.trace(&quot;Sent produce request to &#123;&#125;: &#123;&#125;&quot;, nodeId, requestBuilder);</span><br></pre></td></tr></table></figure><p>这段代码就简单很多，总来起来就是，将 batches 中 leader 为同一个 node 的所有 RecordBatch 放在一个请求中进行发送。</p><h3 id="最后"><a class="markdownIt-Anchor" href="#最后"></a> 最后</h3><p>本文是对 Kafka Producer 端发送模型的一个简单分析，下一篇文章将会详细介绍 metadata 相关的内容，包括 metadata 的内容以及在 Producer 端 metadata 的更新机制。</p><p>转自：<a href="https://zhuanlan.zhihu.com/p/66190242" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/66190242</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;kafka是一个分布式的消息中间件，目前应用十分广泛。看源码不仅可以了解其底层的细节，同时，在看代码时，也能跟
      
    
    </summary>
    
      <category term="大数据" scheme="yihao.ml/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="kafka" scheme="yihao.ml/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>离职总结</title>
    <link href="yihao.ml/2019/08/28/2019%E2%80%9308-28-%E7%A6%BB%E8%81%8C%E6%80%BB%E7%BB%93/"/>
    <id>yihao.ml/2019/08/28/2019–08-28-离职总结/</id>
    <published>2019-08-28T09:46:53.557Z</published>
    <updated>2019-11-29T12:20:47.708Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>昨天我打开QQ，看到了大学室友XXX的名字，就会想起当时他发生意外的场景，生命真的太脆弱、太短暂了。不忘初心，我能确切的感受到我还活着。</p><p>如今已经快要奔3了，我想趁着自己还能拼动，努力去闯一闯。希望未来的我不会后悔，因为后悔了它就会在那，会一直伴随直到终老。</p><p>我的离职很多人反对，朋友说在公司邻近上市，员工分发股权的时候离职是不明智的选择。</p><p>其实人生会经历很多这样的选择，在岔路上到底选哪条路呢？掺杂太多算计，往往可能要吃亏，其实我只遵循只有一个，就是随心。</p><p>有人说钱很重要，你不能跟钱过不去，这没啥毛病，谁会和钱过不去呢？我的观点只是如果一个人把钱看的很重，他应该赚不到钱。</p><p>有时候我们算错了，其实在做选择时，拿感受算账才是最正确的，只要自己感觉快乐就可以了。假如我干了我喜欢的事，而且我还能养活自己，那我就很快乐，其他的都无所谓。就算选错了，又有什么关系呢，吸取经验，补齐自己的不足就行了，它会将成为我人生的阅历。</p><p>刚毕业的我没有像其他人那样,很幸运地进入到一个大公司，但是这里不能否认小公司对成长的重要性。大公司也是小公司成长起来的，正是因为这次的经历，让我知道了小公司成长的过程，以及其中的辛酸；让我知道了在非标特殊情况下，如何应对各种问题；同样也让我知道了抉择的重要性，对公司起什么样的作用；</p><p>这些东西，在大公司中，对于稚嫩的毕业生来说是完全不可能接触到的，这份工作经历对我影响还是蛮大的。</p><p>除了好处，小公司也有很多弊端，小公司中技术往往都不是很让人满意。公司中的非标太多，因此我们需要擦亮眼睛，认清楚哪些是对的，哪些是错的。</p><p>在试错中成长，也是个不错的选择。两年，从刚入职只能做小功能模块，到现在的独当一面，这很显然就是进步。</p><p>大大小小的功能模块及每天不停的编码，让我的对代码的认知上升到了新高度、在J2EE行业中沉淀了大量的经验。</p><p>我不再追求完成功能，在完成功能的同时，也会注重代码整体结构的设计，想着法子让算法与应用相结合以此来提高代码的执行效率，想办法优雅的封装实现代码的复用来节约开发周期等；</p><p>因为公司的业务量不是很大，因此我有机会学习一些新东西。</p><p>在这两年间，我学习并深入了解了大数据相关的知识，比如MR、Yarn、Hive、Hbase、Storm、Spark等等，了解了机器学习及部分算法knn、贝叶斯、回归等算法，巩固了大学学的数据结构。</p><p>学习了python、scala、GO等新的编程语言，折腾出了很多有趣的小玩意，比如：自动下载器（实现百度网盘到移动硬盘内容的无缝对接）、人脸识别（使用Raspberry PI微型计算机+OpenCV）、大数据实时日志分析系统等。</p><p>好了就这样了。写给未来的自己,继续努力！</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;昨天我打开QQ，看到了大学室友XXX的名字，就会想起当时他发生意外的场景，生命真的太脆弱、太短暂了。不忘初心，
      
    
    </summary>
    
      <category term="其他" scheme="yihao.ml/categories/%E5%85%B6%E4%BB%96/"/>
    
    
  </entry>
  
  <entry>
    <title>神经网络：基本分类[转]</title>
    <link href="yihao.ml/2019/08/20/2019%E2%80%9308-20-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%9F%BA%E6%9C%AC%E5%88%86%E7%B1%BB%5B%E8%BD%AC%5D/"/>
    <id>yihao.ml/2019/08/20/2019–08-20-神经网络：基本分类[转]/</id>
    <published>2019-08-20T22:39:00.000Z</published>
    <updated>2019-11-29T12:20:47.707Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>代码式例：<a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/basic_classification.ipynb" target="_blank" rel="noopener">Run in Gogle Colab</a> / <a href="https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/basic_classification.ipynb" target="_blank" rel="noopener">View source on Github</a></p><p>本指南转自TensorFlow官网。主要训练了一个神经网络模型，来对服装图像进行分类，例如运动鞋和衬衫。如果您不了解所有细节也不需要担心，这是一个对完整TensorFlow项目的简要概述，相关的细节会在需要时进行解释</p><p>本指南使用<code>tf.keras</code>，这是一个用于在TensorFlow中构建和训练模型的高级API。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import, division, print_function, unicode_literals</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入TensorFlow和tf.keras</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入辅助库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure><p>结果如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2.0</span><span class="number">.0</span>-beta1</span><br></pre></td></tr></table></figure><h3 id="导入fashion-mnist数据集"><a class="markdownIt-Anchor" href="#导入fashion-mnist数据集"></a> 导入Fashion MNIST数据集</h3><p>本指南使用Fashion MNIST 数据集，其中包含了10个类别中共70,000张灰度图像。图像包含了低分辨率（28 x 28像素）的单个服装物品，如下所示:<br><img src="https://i.loli.net/2019/08/20/jmXkbzvKDIF9fid.png" alt="Figure 1. Fashion-MNIST samples (by Zalando, MIT License)."></p><p>Fashion MNIST 旨在替代传统的MNIST数据集 — 它经常被作为机器学习在计算机视觉方向的&quot;Hello, World&quot;。MNIST数据集包含手写数字（0,1,2等）的图像，其格式与我们在此处使用的服装相同。</p><p>本指南使用Fashion MNIST进行多样化，因为它比普通的MNIST更具挑战性。两个数据集都相对较小，用于验证算法是否按预期工作。它们是测试和调试代码的良好起点。</p><p>我们将使用60,000张图像来训练网络和10,000张图像来评估网络模型学习图像分类任务的准确程度。您可以直接从TensorFlow使用Fashion MNIST，只需导入并加载数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fashion_mnist = keras.datasets.fashion_mnist</span><br><span class="line"></span><br><span class="line">(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()</span><br></pre></td></tr></table></figure><p>结果:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Downloading data <span class="keyword">from</span> https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz</span><br><span class="line"><span class="number">32768</span>/<span class="number">29515</span> [=================================] - <span class="number">0</span>s <span class="number">0</span>us/step</span><br><span class="line">Downloading data <span class="keyword">from</span> https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz</span><br><span class="line"><span class="number">26427392</span>/<span class="number">26421880</span> [==============================] - <span class="number">0</span>s <span class="number">0</span>us/step</span><br><span class="line">Downloading data <span class="keyword">from</span> https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz</span><br><span class="line"><span class="number">8192</span>/<span class="number">5148</span> [===============================================] - <span class="number">0</span>s <span class="number">0</span>us/step</span><br><span class="line">Downloading data <span class="keyword">from</span> https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz</span><br><span class="line"><span class="number">4423680</span>/<span class="number">4422102</span> [==============================] - <span class="number">0</span>s <span class="number">0</span>us/step</span><br></pre></td></tr></table></figure><p>加载数据集并返回四个NumPy数组:</p><ul><li>train_images和train_labels数组是训练集—这是模型用来学习的数据。</li><li>模型通过测试集进行测试, 即test_images与 test_labels两个数组。</li></ul><p>图像是28x28 NumPy数组，像素值介于0到255之间。labels是一个整数数组，数值介于0到9之间。这对应了图像所代表的服装的类别:</p><table><thead><tr><th>标签</th><th>类别</th></tr></thead><tbody><tr><td>0</td><td>T-shirt/top</td></tr><tr><td>1</td><td>Trouser</td></tr><tr><td>2</td><td>Pullover</td></tr><tr><td>3</td><td>Dress</td></tr><tr><td>4</td><td>Coat</td></tr><tr><td>5</td><td>Sandal</td></tr><tr><td>6</td><td>Shirt</td></tr><tr><td>7</td><td>Sneaker</td></tr><tr><td>8</td><td>Bag</td></tr><tr><td>9</td><td>Ankle boot</td></tr></tbody></table><p>每个图像都映射到一个标签。由于类别名称不包含在数据集中,因此把他们存储在这里以便在绘制图像时使用:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class_names = [<span class="string">'T-shirt/top'</span>, <span class="string">'Trouser'</span>, <span class="string">'Pullover'</span>, <span class="string">'Dress'</span>, <span class="string">'Coat'</span>,<span class="string">'Sandal'</span>, <span class="string">'Shirt'</span>, <span class="string">'Sneaker'</span>, <span class="string">'Bag'</span>, <span class="string">'Ankle boot'</span>]</span><br></pre></td></tr></table></figure><h3 id="探索数据"><a class="markdownIt-Anchor" href="#探索数据"></a> 探索数据</h3><p>让我们在训练模型之前探索数据集的格式。以下显示训练集中有60,000个图像，每个图像表示为28 x 28像素:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_images.shape</span><br></pre></td></tr></table></figure><p>同样，训练集中有60,000个标签:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(train_labels)</span><br></pre></td></tr></table></figure><p>每个标签都是0到9之间的整数:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_labels</span><br></pre></td></tr></table></figure><p>测试集中有10,000个图像。 同样，每个图像表示为28×28像素:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_images.shape</span><br></pre></td></tr></table></figure><p>测试集包含10,000个图像标签:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(test_labels)</span><br></pre></td></tr></table></figure><h3 id="数据预处理"><a class="markdownIt-Anchor" href="#数据预处理"></a> 数据预处理</h3><p>在训练网络之前必须对数据进行预处理。 如果您检查训练集中的第一个图像，您将看到像素值落在0到255的范围内:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.figure()</span><br><span class="line">plt.imshow(train_images[<span class="number">0</span>])</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/08/20/baylZYDAmQNUT4L.png" alt="2.png"></p><p>在馈送到神经网络模型之前，我们将这些值缩放到0到1的范围。为此，我们将像素值值除以255。重要的是，对训练集和测试集要以相同的方式进行预处理:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_images = train_images / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">test_images = test_images / <span class="number">255.0</span></span><br></pre></td></tr></table></figure><p>显示训练集中的前25个图像，并在每个图像下方显示类名。验证数据格式是否正确，我们是否已准备好构建和训练网络。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">25</span>):</span><br><span class="line">    plt.subplot(<span class="number">5</span>,<span class="number">5</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    plt.grid(<span class="literal">False</span>)</span><br><span class="line">    plt.imshow(train_images[i], cmap=plt.cm.binary)</span><br><span class="line">    plt.xlabel(class_names[train_labels[i]])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/08/20/kXFbnSYayO19lpZ.png" alt="3.png"></p><h3 id="构建模型"><a class="markdownIt-Anchor" href="#构建模型"></a> 构建模型</h3><p>构建神经网络需要配置模型的层，然后编译模型。</p><p><strong>设置网络层</strong></p><p>一个神经网络最基本的组成部分便是网络层。网络层从提供给他们的数据中提取表示，并期望这些表示对当前的问题更加有意义</p><p>大多数深度学习是由串连在一起的网络层所组成。大多数网络层，例如<code>tf.keras.layers.Dense</code>，具有在训练期间学习的参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential([</span><br><span class="line">    keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">    keras.layers.Dense(<span class="number">128</span>, activation=tf.nn.relu),</span><br><span class="line">    keras.layers.Dense(<span class="number">10</span>, activation=tf.nn.softmax)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p>网络中的第一层, <code>tf.keras.layers.Flatten</code>, 将图像格式从一个二维数组(包含着28x28个像素)转换成为一个包含着28 * 28 = 784个像素的一维数组。可以将这个网络层视为它将图像中未堆叠的像素排列在一起。这个网络层没有需要学习的参数;它仅仅对数据进行格式化。</p><p>在像素被展平之后，网络由一个包含有两个tf.keras.layers.Dense网络层的序列组成。他们被称作稠密链接层或全连接层。 第一个Dense网络层包含有128个节点(或被称为神经元)。第二个(也是最后一个)网络层是一个包含10个节点的softmax层—它将返回包含10个概率分数的数组，总和为1。每个节点包含一个分数，表示当前图像属于10个类别之一的概率。</p><p><strong>编译模型</strong></p><p>在模型准备好进行训练之前，它还需要一些配置。这些是在模型的编译(compile)步骤中添加的:</p><ul><li>损失函数 —这可以衡量模型在培训过程中的准确程度。 我们希望将此函数最小化以&quot;驱使&quot;模型朝正确的方向拟合。</li><li>优化器 —这就是模型根据它看到的数据及其损失函数进行更新的方式。’</li><li>评价方式 —用于监控训练和测试步骤。以下示例使用准确率(accuracy)，即正确分类的图像的分数。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure><h3 id="训练模型"><a class="markdownIt-Anchor" href="#训练模型"></a> 训练模型</h3><p>训练神经网络模型需要以下步骤:</p><pre><code>1. 将训练数据提供给模型 - 在本案例中，他们是train_images和train_labels数组。2. 模型学习如何将图像与其标签关联3. 我们使用模型对测试集进行预测, 在本案例中为test_images数组。我们验证预测结果是否匹配test_labels数组中保存的标签。4. 通过调用model.fit方法来训练模型 — 模型对训练数据进行&quot;拟合&quot;。</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(train_images, train_labels, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><p>结果:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">WARNING: Logging before flag parsing goes to stderr.</span><br><span class="line">W0703 <span class="number">00</span>:<span class="number">57</span>:<span class="number">16.227570</span> <span class="number">140360607328000</span> deprecation.py:<span class="number">323</span>] From /tmpfs/src/tf_docs_env/lib/python3<span class="number">.5</span>/site-packages/tensorflow/python/ops/math_grad.py:<span class="number">1250</span>: add_dispatch_support.&lt;locals&gt;.wrapper (<span class="keyword">from</span> tensorflow.python.ops.array_ops) <span class="keyword">is</span> deprecated <span class="keyword">and</span> will be removed <span class="keyword">in</span> a future version.</span><br><span class="line">Instructions <span class="keyword">for</span> updating:</span><br><span class="line">Use tf.where <span class="keyword">in</span> <span class="number">2.0</span>, which has the same broadcast rule <span class="keyword">as</span> np.where</span><br><span class="line"></span><br><span class="line">Train on <span class="number">60000</span> samples</span><br><span class="line">Epoch <span class="number">1</span>/<span class="number">5</span></span><br><span class="line"><span class="number">60000</span>/<span class="number">60000</span> [==============================] - <span class="number">5</span>s <span class="number">85</span>us/sample - loss: <span class="number">0.4949</span> - accuracy: <span class="number">0.8267</span></span><br><span class="line">Epoch <span class="number">2</span>/<span class="number">5</span></span><br><span class="line"><span class="number">60000</span>/<span class="number">60000</span> [==============================] - <span class="number">6</span>s <span class="number">92</span>us/sample - loss: <span class="number">0.3753</span> - accuracy: <span class="number">0.8641</span></span><br><span class="line">Epoch <span class="number">3</span>/<span class="number">5</span></span><br><span class="line"><span class="number">60000</span>/<span class="number">60000</span> [==============================] - <span class="number">5</span>s <span class="number">89</span>us/sample - loss: <span class="number">0.3355</span> - accuracy: <span class="number">0.8784</span></span><br><span class="line">Epoch <span class="number">4</span>/<span class="number">5</span></span><br><span class="line"><span class="number">60000</span>/<span class="number">60000</span> [==============================] - <span class="number">4</span>s <span class="number">72</span>us/sample - loss: <span class="number">0.3136</span> - accuracy: <span class="number">0.8855</span></span><br><span class="line">Epoch <span class="number">5</span>/<span class="number">5</span></span><br><span class="line"><span class="number">60000</span>/<span class="number">60000</span> [==============================] - <span class="number">4</span>s <span class="number">69</span>us/sample - loss: <span class="number">0.2955</span> - accuracy: <span class="number">0.8921</span></span><br><span class="line"></span><br><span class="line">&lt;tensorflow.python.keras.callbacks.History at <span class="number">0x7fa81c2c1b38</span>&gt;</span><br></pre></td></tr></table></figure><p>随着模型训练，将显示损失和准确率等指标。该模型在训练数据上达到约0.88(或88％)的准确度。</p><h3 id="评估准确率"><a class="markdownIt-Anchor" href="#评估准确率"></a> 评估准确率</h3><p>接下来，比较模型在测试数据集上的执行情况:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_loss, test_acc = model.evaluate(test_images, test_labels)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Test accuracy:'</span>, test_acc)</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">10000</span>/<span class="number">10000</span> [==============================] - <span class="number">1</span>s <span class="number">53</span>us/sample - loss: <span class="number">0.3489</span> - accuracy: <span class="number">0.8713</span></span><br><span class="line">Test accuracy: <span class="number">0.8713</span></span><br></pre></td></tr></table></figure><p>事实证明，测试数据集的准确性略低于训练数据集的准确性。训练精度和测试精度之间的差距是过拟合的一个例子。过拟合是指机器学习模型在新数据上的表现比在训练数据上表现更差。</p><h3 id="进行预测"><a class="markdownIt-Anchor" href="#进行预测"></a> 进行预测</h3><p>通过训练模型，我们可以使用它来预测某些图像。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predictions = model.predict(test_images)</span><br></pre></td></tr></table></figure><p>在此，模型已经预测了测试集中每个图像的标签。我们来看看第一个预测:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predictions[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([<span class="number">6.6858855e-05</span>, <span class="number">2.5964803e-07</span>, <span class="number">5.3627105e-06</span>, <span class="number">4.5019146e-06</span>,</span><br><span class="line">       <span class="number">2.7420206e-06</span>, <span class="number">4.7881842e-02</span>, <span class="number">2.3233067e-04</span>, <span class="number">5.4705784e-02</span>,</span><br><span class="line">       <span class="number">8.5581087e-05</span>, <span class="number">8.9701480e-01</span>], dtype=float32)</span><br></pre></td></tr></table></figure><p>预测是10个数字的数组。这些描述了模型的&quot;信心&quot;，即图像对应于10种不同服装中的每一种。我们可以看到哪个标签具有最高的置信度值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.argmax(predictions[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><p>9</p><p>因此，模型最有信心的是这个图像是ankle boot，或者 class_names[9]。 我们可以检查测试标签，看看这是否正确:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_labels[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>9</p><p>我们可以用图表来查看全部10个类别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_image</span><span class="params">(i, predictions_array, true_label, img)</span>:</span></span><br><span class="line">  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]</span><br><span class="line">  plt.grid(<span class="literal">False</span>)</span><br><span class="line">  plt.xticks([])</span><br><span class="line">  plt.yticks([])</span><br><span class="line">  </span><br><span class="line">  plt.imshow(img, cmap=plt.cm.binary)</span><br><span class="line">  </span><br><span class="line">  predicted_label = np.argmax(predictions_array)</span><br><span class="line">  <span class="keyword">if</span> predicted_label == true_label:</span><br><span class="line">    color = <span class="string">'blue'</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    color = <span class="string">'red'</span></span><br><span class="line">  </span><br><span class="line">  plt.xlabel(<span class="string">"&#123;&#125; &#123;:2.0f&#125;% (&#123;&#125;)"</span>.format(class_names[predicted_label],</span><br><span class="line">                                <span class="number">100</span>*np.max(predictions_array),</span><br><span class="line">                                class_names[true_label]),</span><br><span class="line">                                color=color)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_value_array</span><span class="params">(i, predictions_array, true_label)</span>:</span></span><br><span class="line">  predictions_array, true_label = predictions_array[i], true_label[i]</span><br><span class="line">  plt.grid(<span class="literal">False</span>)</span><br><span class="line">  plt.xticks([])</span><br><span class="line">  plt.yticks([])</span><br><span class="line">  thisplot = plt.bar(range(<span class="number">10</span>), predictions_array, color=<span class="string">"#777777"</span>)</span><br><span class="line">  plt.ylim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">  predicted_label = np.argmax(predictions_array)</span><br><span class="line">  </span><br><span class="line">  thisplot[predicted_label].set_color(<span class="string">'red'</span>)</span><br><span class="line">  thisplot[true_label].set_color(<span class="string">'blue'</span>)</span><br></pre></td></tr></table></figure><p>让我们看看第0个图像，预测和预测数组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">0</span></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>,<span class="number">3</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plot_image(i, predictions, test_labels, test_images)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plot_value_array(i, predictions,  test_labels)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/08/20/vJHqX6LogKsxzjW.png" alt="4.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">12</span></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>,<span class="number">3</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plot_image(i, predictions, test_labels, test_images)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plot_value_array(i, predictions,  test_labels)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/08/20/J7YiK4uWB68bLsG.png" alt="5.png"></p><p>让我们绘制几个图像及其预测结果。正确的预测标签是蓝色的，不正确的预测标签是红色的。该数字给出了预测标签的百分比(满分100)。请注意，即使非常自信，也可能出错。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 绘制前X个测试图像，预测标签和真实标签</span></span><br><span class="line"><span class="comment"># 以蓝色显示正确的预测，红色显示不正确的预测</span></span><br><span class="line">num_rows = <span class="number">5</span></span><br><span class="line">num_cols = <span class="number">3</span></span><br><span class="line">num_images = num_rows*num_cols</span><br><span class="line">plt.figure(figsize=(<span class="number">2</span>*<span class="number">2</span>*num_cols, <span class="number">2</span>*num_rows))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(num_images):</span><br><span class="line">  plt.subplot(num_rows, <span class="number">2</span>*num_cols, <span class="number">2</span>*i+<span class="number">1</span>)</span><br><span class="line">  plot_image(i, predictions, test_labels, test_images)</span><br><span class="line">  plt.subplot(num_rows, <span class="number">2</span>*num_cols, <span class="number">2</span>*i+<span class="number">2</span>)</span><br><span class="line">  plot_value_array(i, predictions, test_labels)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/08/20/vN8hQ4SVILftudE.png" alt="6.png"></p><p>最后，使用训练的模型对单个图像进行预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从测试数据集中获取图像</span></span><br><span class="line">img = test_images[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">print(img.shape)</span><br></pre></td></tr></table></figure><p>(28, 28)</p><p><code>tf.keras</code>模型经过优化，可以一次性对批量,或者一个集合的数据进行预测。因此，即使我们使用单个图像，我们也需要将其添加到列表中:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将图像添加到批次中，即使它是唯一的成员。</span></span><br><span class="line">img = (np.expand_dims(img,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">print(img.shape)</span><br></pre></td></tr></table></figure><p>(1, 28, 28)</p><p>现在来预测图像:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">predictions_single = model.predict(img)</span><br><span class="line"></span><br><span class="line">print(predictions_single)</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">6.6858927e-05</span> <span class="number">2.5964729e-07</span> <span class="number">5.3627055e-06</span> <span class="number">4.5019060e-06</span> <span class="number">2.7420206e-06</span></span><br><span class="line">  <span class="number">4.7881793e-02</span> <span class="number">2.3233047e-04</span> <span class="number">5.4705758e-02</span> <span class="number">8.5581087e-05</span> <span class="number">8.9701480e-01</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plot_value_array(<span class="number">0</span>, predictions_single, test_labels)</span><br><span class="line">plt.xticks(range(<span class="number">10</span>), class_names, rotation=<span class="number">45</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/08/20/aEGWf5qzSgkbAQV.png" alt="9.png"></p><p>model.predict返回一个包含列表的列表，每个图像对应一个列表的数据。获取批次中我们(仅有的)图像的预测:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">prediction_result = np.argmax(predictions_single[<span class="number">0</span>])</span><br><span class="line">print(prediction_result)</span><br></pre></td></tr></table></figure><p>9</p><p>而且，和之前一样，模型预测标签为9。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;代码式例：&lt;a href=&quot;https://colab.research.google.com/github/
      
    
    </summary>
    
      <category term="机器学习" scheme="yihao.ml/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>HiveSQL优化</title>
    <link href="yihao.ml/2019/08/17/2019%E2%80%9308-17-HiveSQL%E4%BC%98%E5%8C%96/"/>
    <id>yihao.ml/2019/08/17/2019–08-17-HiveSQL优化/</id>
    <published>2019-08-17T21:54:00.000Z</published>
    <updated>2019-11-29T12:20:47.707Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>下面列举一些常用的SQL优化方案</p><h2 id="sql引起的数据倾斜"><a class="markdownIt-Anchor" href="#sql引起的数据倾斜"></a> sql引起的数据倾斜</h2><p>数据倾斜会导致某个Reduce运行过慢影响到整体的运行时长。通常在join和group by时，会出现这样的问题</p><ol><li>join引起的数据倾斜,下面操作会将一个job变为两个job执行HQL</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">如果是join过程出现倾斜，应该设置为<span class="literal">true</span></span></span><br><span class="line">set hive.optimize.skewjoin=true;</span><br><span class="line"><span class="meta">#</span><span class="bash">这个是join的键对应的记录条数超过这个值则会进行优化</span></span><br><span class="line">set hive.skewjoin.key=100000;</span><br></pre></td></tr></table></figure><ol start="2"><li>group by key引起的数据倾斜</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 如果group by过程出现倾斜应该设置为<span class="literal">true</span></span></span><br><span class="line">set hive.groupby.skewindata=true;</span><br><span class="line"><span class="meta">#</span><span class="bash">这个是group的键对应的记录条数超过这个值则会进行优化</span></span><br><span class="line">set hive.groupby.mapaggr.checkinterval=100000;</span><br></pre></td></tr></table></figure><h2 id="mapjoinmap端执行join"><a class="markdownIt-Anchor" href="#mapjoinmap端执行join"></a> mapjoin(map端执行join）</h2><p>针对应用场景合理使用MapJoin也很重要。Map Join可以解决数据倾斜问题，因为没有Reduce Task了;只运行Map Task，相比多运行Reduce Task来说省时间。</p><p>启动方式一：(自动)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set.hive.auto.convert.join = true;</span><br><span class="line"><span class="meta">#</span><span class="bash">默认值是25mb小表小于25mb自动启动mapjoin </span></span><br><span class="line">hive.mapjoin.smalltable.filesize=25000000</span><br></pre></td></tr></table></figure><p>启动方式二：(手动）</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="comment">/*+mapjoin(A)*/</span> f.a,f.b <span class="keyword">from</span> A t <span class="keyword">join</span> B f <span class="keyword">on</span> (f.a=t.a)</span><br></pre></td></tr></table></figure><h2 id="bucketjoin"><a class="markdownIt-Anchor" href="#bucketjoin"></a> bucketjoin</h2><p>合理利用桶分区很重要，因为它可以避免全表检索，在大数据场景中全表检索意味着什么应该可以想象…</p><p>在满足下面两个情况时使用：</p><ul><li>1.两个表以相同方式划分桶</li><li>2.两个表的桶个数是倍数关系</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">order</span>(cid <span class="built_in">int</span>,price <span class="built_in">float</span>) clustered <span class="keyword">by</span>(cid)   <span class="keyword">into</span> <span class="number">32</span> buckets;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> customer(<span class="keyword">id</span> <span class="built_in">int</span>,<span class="keyword">first</span> <span class="keyword">string</span>) clustered <span class="keyword">by</span>(<span class="keyword">id</span>)   <span class="keyword">into</span> <span class="number">32</span>/<span class="number">64</span> buckets;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> price <span class="keyword">from</span> <span class="keyword">order</span> t <span class="keyword">join</span> customer s <span class="keyword">on</span> t.cid=s.id;</span><br></pre></td></tr></table></figure><h2 id="where条件优化"><a class="markdownIt-Anchor" href="#where条件优化"></a> where条件优化</h2><p>尽可能早的筛掉更多的数据。</p><p>优化前（关系数据库不用考虑会自动优化）：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> m.cid,u.id <span class="keyword">from</span> <span class="keyword">order</span> m <span class="keyword">join</span> customer u <span class="keyword">on</span> m.cid =u.id <span class="keyword">where</span> m.dt=<span class="string">'2019-08-18'</span>;</span><br></pre></td></tr></table></figure><p>优化后(where条件在map端执行而不是在reduce端执行）：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> m.cid,u.id <span class="keyword">from</span> （<span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">order</span> <span class="keyword">where</span> dt=<span class="string">'2019-08-18'</span>） m <span class="keyword">join</span> customer u <span class="keyword">on</span> m.cid =u.id;</span><br></pre></td></tr></table></figure><h2 id="count-distinct优化"><a class="markdownIt-Anchor" href="#count-distinct优化"></a> count distinct优化</h2><p>只有一个reduce，先去重再count负担比较大;解决方案是：启动两个job，一个job负责子查询(可以有多个reduce)，另一个job负责count(1)</p><p>优化前：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">distinct</span> <span class="keyword">id</span>) <span class="keyword">from</span> tablename;</span><br></pre></td></tr></table></figure><p>优化后：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="number">1</span>) <span class="keyword">from</span> (<span class="keyword">select</span> <span class="keyword">distinct</span> <span class="keyword">id</span> <span class="keyword">from</span> tablename) tmp;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="number">1</span>) <span class="keyword">from</span> (<span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> tablename <span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">id</span>) tmp;</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span> mapred.reduce.tasks=<span class="number">3</span>;</span><br></pre></td></tr></table></figure><h2 id="合理使用union-all"><a class="markdownIt-Anchor" href="#合理使用union-all"></a> 合理使用union all</h2><p>优化前：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a,<span class="keyword">sum</span>(b),<span class="keyword">count</span>(<span class="keyword">distinct</span> c),<span class="keyword">count</span>(<span class="keyword">distinct</span> d) <span class="keyword">from</span> <span class="keyword">test</span> <span class="keyword">group</span> <span class="keyword">by</span> a;</span><br></pre></td></tr></table></figure><p>优化后：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a,<span class="keyword">sum</span>(b) <span class="keyword">as</span> b,<span class="keyword">count</span>(c) <span class="keyword">as</span> c,<span class="keyword">count</span>(d) <span class="keyword">as</span> d <span class="keyword">from</span></span><br><span class="line">（</span><br><span class="line"><span class="keyword">select</span> a, <span class="number">0</span> <span class="keyword">as</span> b,c,<span class="literal">null</span> <span class="keyword">as</span> d <span class="keyword">from</span> <span class="keyword">test</span> <span class="keyword">group</span> <span class="keyword">by</span> a,c</span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> a,<span class="number">0</span> <span class="keyword">as</span> b, <span class="literal">null</span> <span class="keyword">as</span> c,d <span class="keyword">from</span> <span class="keyword">test</span> <span class="keyword">group</span> <span class="keyword">by</span> a,d</span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> a, b,<span class="literal">null</span> <span class="keyword">as</span> c ,<span class="literal">null</span> <span class="keyword">as</span> d <span class="keyword">from</span> <span class="keyword">test</span>) tmp <span class="keyword">group</span> <span class="keyword">by</span> a;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;下面列举一些常用的SQL优化方案&lt;/p&gt;&lt;h2 id=&quot;sql引起的数据倾斜&quot;&gt;&lt;a class=&quot;markd
      
    
    </summary>
    
      <category term="大数据" scheme="yihao.ml/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
  </entry>
  
  <entry>
    <title>HDMI连接Raspberry</title>
    <link href="yihao.ml/2019/07/29/2019%E2%80%9307-29-HDMI%E8%BF%9E%E6%8E%A5Raspberry/"/>
    <id>yihao.ml/2019/07/29/2019–07-29-HDMI连接Raspberry/</id>
    <published>2019-07-29T22:26:00.000Z</published>
    <updated>2019-11-29T12:20:47.706Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>通常情况下，树莓派会自动检测显示器的类型并修改配置。但有时，自动检测的结果可能不正确。如果你的树莓派连接到电视上但没有任何显示的话，你要考虑手动修改树莓派的显示配置了</p><p><img src="https://i.loli.net/2019/07/30/5d3f1b5a7dc4c45534.jpeg" alt="https://i.loli.net/2019/07/30/5d3f1b5a7dc4c45534.jpeg"></p><p>下面我们手动修改/boot/config.txt文件。记得修改前备份一个，以下是参数文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> For more options and information see</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> http://rpf.io/configtxt</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Some settings may impact device functionality. See link above <span class="keyword">for</span> details</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> uncomment <span class="keyword">if</span> you get no picture on HDMI <span class="keyword">for</span> a default <span class="string">"safe"</span> mode</span></span><br><span class="line"><span class="meta">#</span><span class="bash">hdmi_safe=1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> uncomment this <span class="keyword">if</span> your display has a black border of unused pixels visible</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> and your display can output without overscan</span></span><br><span class="line">disable_overscan=1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> uncomment the following to adjust overscan. Use positive numbers <span class="keyword">if</span> console</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> goes off screen, and negative <span class="keyword">if</span> there is too much border</span></span><br><span class="line"><span class="meta">#</span><span class="bash">overscan_left=16</span></span><br><span class="line"><span class="meta">#</span><span class="bash">overscan_right=16</span></span><br><span class="line"><span class="meta">#</span><span class="bash">overscan_top=16</span></span><br><span class="line"><span class="meta">#</span><span class="bash">overscan_bottom=16</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> uncomment to force a console size. By default it will be display<span class="string">'s size minus</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> overscan.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">framebuffer_width=1280</span></span><br><span class="line"><span class="meta">#</span><span class="bash">framebuffer_height=720</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> uncomment <span class="keyword">if</span> hdmi display is not detected and composite is being output</span></span><br><span class="line">hdmi_force_hotplug=1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> uncomment to force a specific HDMI mode (this will force VGA)</span></span><br><span class="line">hdmi_group=1</span><br><span class="line">hdmi_mode=4</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> uncomment to force a HDMI mode rather than DVI. This can make audio work <span class="keyword">in</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> DMT (computer monitor) modes</span></span><br><span class="line">hdmi_drive=2</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> uncomment to increase signal to HDMI, <span class="keyword">if</span> you have interference, blanking, or</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> no display</span></span><br><span class="line">config_hdmi_boost=4</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> uncomment <span class="keyword">for</span> composite PAL</span></span><br><span class="line"><span class="meta">#</span><span class="bash">sdtv_mode=2</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">uncomment to overclock the arm. 700 MHz is the default.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">arm_freq=800</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Uncomment some or all of these to <span class="built_in">enable</span> the optional hardware interfaces</span></span><br><span class="line"><span class="meta">#</span><span class="bash">dtparam=i2c_arm=on</span></span><br><span class="line"><span class="meta">#</span><span class="bash">dtparam=i2s=on</span></span><br><span class="line"><span class="meta">#</span><span class="bash">dtparam=spi=on</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Uncomment this to <span class="built_in">enable</span> the lirc-rpi module</span></span><br><span class="line"><span class="meta">#</span><span class="bash">dtoverlay=lirc-rpi</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Additional overlays and parameters are documented /boot/overlays/README</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Enable audio (loads snd_bcm2835)</span></span><br><span class="line">dtparam=audio=on</span><br><span class="line">start_x=1</span><br><span class="line">gpu_mem=128</span><br><span class="line">enable_uart=1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">disable_camera_led=1</span></span><br><span class="line">hdmi_ignore_edid=0xa5000080</span><br></pre></td></tr></table></figure><p>看这个<a href="https://wenku.baidu.com/view/a8a1554e71fe910ef02df893.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/a8a1554e71fe910ef02df893.html</a>，学一下各个参数详解</p><p>学完之后了解一下怎么调hdmi_mode这个参数<a href="https://zhidao.baidu.com/question/519865882625562245.html" target="_blank" rel="noopener">https://zhidao.baidu.com/question/519865882625562245.html</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;通常情况下，树莓派会自动检测显示器的类型并修改配置。但有时，自动检测的结果可能不正确。如果你的树莓派连接到电视
      
    
    </summary>
    
      <category term="物联网" scheme="yihao.ml/categories/%E7%89%A9%E8%81%94%E7%BD%91/"/>
    
    
  </entry>
  
  <entry>
    <title>Google Colab</title>
    <link href="yihao.ml/2019/07/23/2019%E2%80%9307-23-Google%20Colab/"/>
    <id>yihao.ml/2019/07/23/2019–07-23-Google Colab/</id>
    <published>2019-07-23T23:34:00.000Z</published>
    <updated>2019-11-29T12:20:47.706Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><h3 id="训练模型太慢怎么办"><a class="markdownIt-Anchor" href="#训练模型太慢怎么办"></a> 训练模型太慢怎么办？</h3><p>训练模型的时间，好点的用1小时2小时，遇到稍复杂的得等1天甚至2天。训练后的模型，如果不满足要求，还得再反复调整，再来一遍…这简直是个噩梦有么有。去某宝、JD上搜一搜，一台上万谁买的起。对于我们这些穷得揭不开锅的苦比党来说，Google Colab可以说是我们的福音！</p><h3 id="google-golab"><a class="markdownIt-Anchor" href="#google-golab"></a> Google Golab</h3><p>Colaboratory 是一款研究工具，用于进行机器学习和研究。它是一个 Jupyter 笔记本环境，重点是它不需要进行任何设置就可以跑代码，而且性能方面Google提供了Tesla K80 GPU，很给力了。而且它还是永久免费的，仿佛发现了新大陆ヾ(≧O≦)〃，虽然不知道性能到底怎么样，但是跟我这用了5年的烂本子比，已经不知道好到哪去了。</p><h3 id="官网"><a class="markdownIt-Anchor" href="#官网"></a> 官网</h3><p>首先这是Google的东西，想用肯定得FQ，这没啥说的，访问下面链接<a href="https://colab.research.google.com" target="_blank" rel="noopener">Google Colab</a>。Google Colab 支持Python2和Python3语言;想用R和Scala的小伙伴得忍忍了，Google方面正在研发对他们的支持，后续会开方相关功能。</p><h3 id="记事本"><a class="markdownIt-Anchor" href="#记事本"></a> 记事本</h3><p>写代码我们需要先建个“记事本”，可以通过下面两种方法建立:</p><p>1.第一次进入会弹出一个框，点框下面的 <font color="red">&quot;NEW PYTHON 3 NOTBOOK&quot;新建“记事本”<br><a href="https://i.loli.net/2019/07/23/5d3722e1577ab71988.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2019/07/23/5d3722e1577ab71988.png" alt="snapshot.png"></a></font></p><p>2.这个框关掉以后，左上角找到 File-&gt;New Python 3 Notbook<br><a href="https://i.loli.net/2019/07/23/5d372313881d457467.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2019/07/23/5d372313881d457467.png" alt="file.png"></a></p><h3 id="用例"><a class="markdownIt-Anchor" href="#用例"></a> 用例</h3><p>点击“CODE”创建一个代码片段，你可以创建多个代码片段。</p><p><a href="https://i.loli.net/2019/07/23/5d3728ac90b5852441.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2019/07/23/5d3728ac90b5852441.png" alt="2.png"></a></p><p>下面用Python3 测试一下环境是否正常,试着打印tensorflow版本号：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure><p>点击画的红色框框运行代码<br><a href="https://i.loli.net/2019/07/23/5d372439cf26465483.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2019/07/23/5d372439cf26465483.png" alt="snapshot.png"></a></p><p>参考文档汇总:</p><p><a href="https://research.google.com/colaboratory/faq.html#browsers" target="_blank" rel="noopener">官方问答</a>:<a href="https://research.google.com/colaboratory/faq.html#browsers" target="_blank" rel="noopener">https://research.google.com/colaboratory/faq.html#browsers</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;h3 id=&quot;训练模型太慢怎么办&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#训练模
      
    
    </summary>
    
      <category term="机器学习" scheme="yihao.ml/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>堆排序的应用-优先队列</title>
    <link href="yihao.ml/2019/07/18/2019%E2%80%9307-18-%E5%A0%86%E6%8E%92%E5%BA%8F%E7%9A%84%E5%BA%94%E7%94%A8-%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/"/>
    <id>yihao.ml/2019/07/18/2019–07-18-堆排序的应用-优先队列/</id>
    <published>2019-07-18T23:52:00.000Z</published>
    <updated>2019-11-29T12:20:47.706Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>堆排序在排序复杂性的研究中有着重要的地位，因为它是我们所知的唯一能够同时最优的利用空间和时间的方法-在最坏的情况下它能保证使用～2NlgN次比较和恒定的额外空间。</p><p>在开始了解优先队列之前我们先了解一下堆的特性：</p><p>一个大根堆有这么个特性，它的爸爸总是比它的俩孩子的值大;除了这个最基本的以外，你还要知道第k个元素的左孩子是2k，右孩子是2k+1;知道这个以后，下面我们需要实现两个方法，<font color="red">高效的删除最大元素和插入元素</font>。</p><p>如果新插入一个数，那么根据前面的特性，只需要不断循环的用自身和自己的爸爸（k/2）比较大小，根据比较结果判断是否要交换位置即可;如果要删掉一个最大的数，只需要将根与最后一个数交换位置(因为根是大根堆中最大的数)，将其脱离堆结构，然后将根节点不断和它的孩子（2K、2K+1）比较大小，下沉到合适位置即可；</p><p>为了满足k,2k,2k+1的这种层级关系，后续将舍弃数组下标为0的位置，因为2*0会影响到这种层级关系的判断。</p><p>下面我们说一下下沉（sink）和上浮（swim）的实现方法</p><h3 id="上浮"><a class="markdownIt-Anchor" href="#上浮"></a> 上浮</h3><p>如果堆的有序状态因为某个节点比它的父节点更大而被打破，那么我们就需要通过交换它和它的父节点来修复堆。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">swim</span><span class="params">(<span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(k &gt; <span class="number">1</span> &amp;&amp; less(k/<span class="number">2</span>,k))&#123;</span><br><span class="line">        exch(k/<span class="number">2</span>,k);</span><br><span class="line">        k = k/<span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="下沉"><a class="markdownIt-Anchor" href="#下沉"></a> 下沉</h3><p>与上浮相反，如果堆有序被打破，k节点想要下沉到合适的位置，代码应该这么写。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sink</span><span class="params">(<span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(<span class="number">2</span>*k &lt;= N)&#123;</span><br><span class="line">        <span class="keyword">int</span> j = <span class="number">2</span>*k;</span><br><span class="line">        <span class="keyword">if</span>(j &lt; N &amp;&amp; less(j,j+<span class="number">1</span>)) j++;</span><br><span class="line">        <span class="keyword">if</span>(!less(k,j)) <span class="keyword">break</span>;</span><br><span class="line">        exch(k,j);</span><br><span class="line">        k = j;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="基于堆的优先队列"><a class="markdownIt-Anchor" href="#基于堆的优先队列"></a> 基于堆的优先队列</h3><p>下面我们实现一下堆的优先队列。优先队列由一个基于堆的完全二叉树表示，存储于数组pq[1…N]中,pq[0]不用，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxPQ</span>&lt;<span class="title">Key</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;<span class="title">Key</span>&gt;&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Key[] pq;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> N = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MaxPQ</span><span class="params">(<span class="keyword">int</span> maxN)</span></span>&#123;</span><br><span class="line">        pq = (Key[]) <span class="keyword">new</span> Comparable[maxN + <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> N == <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">size</span> <span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> N;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">(Key v)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        pq[++N] = v;</span><br><span class="line">        swim(N);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Key <span class="title">delMax</span><span class="params">()</span></span>&#123;</span><br><span class="line">        Key max = pq[<span class="number">1</span>];</span><br><span class="line">        exch(<span class="number">1</span>,N--);</span><br><span class="line">        pq[N+<span class="number">1</span>] = <span class="keyword">null</span>;</span><br><span class="line">        sink(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> max;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">less</span><span class="params">(<span class="keyword">int</span> i,<span class="keyword">int</span> j)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> pq[i] &lt; pq[j];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">exch</span><span class="params">(i,j)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        Key t = pq[i];</span><br><span class="line">        pq[i] = pq[j];</span><br><span class="line">        pq[j] = t;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">swim</span><span class="params">(<span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sink</span><span class="params">(<span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在insert()中，将N加1并把新元素添加到数组最后，然后用swim()恢复秩序。在delMax()中。从pq[1]中得到需要返回的元素，然后将pq[N]移动到pq[1],将N减一并用sink()恢复对的秩序。将pq[N+1]设为null，以便GC回收其所占空间。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;堆排序在排序复杂性的研究中有着重要的地位，因为它是我们所知的唯一能够同时最优的利用空间和时间的方法-在最坏的情
      
    
    </summary>
    
      <category term="算法与数据结构" scheme="yihao.ml/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>Hive迁移老数据-动态分区</title>
    <link href="yihao.ml/2019/07/18/2019%E2%80%9307-17-%E8%BF%81%E7%A7%BB%E8%80%81%E6%95%B0%E6%8D%AE%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA/"/>
    <id>yihao.ml/2019/07/18/2019–07-17-迁移老数据动态分区/</id>
    <published>2019-07-18T11:18:55.000Z</published>
    <updated>2019-11-29T12:20:47.705Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>现在有个hive表 dw_revisit_user_d ，创建的时候没有加partitioned by,现在想拓展表中的datestr当分区列。要怎么保证原来数据不丢，并且让原来的数据按datestr分区，以后的数据也按datestr分区？</p><p><a href="https://i.loli.net/2019/07/18/5d2fe458aa59551956.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2019/07/18/5d2fe458aa59551956.png" alt="9DA3BBF8-75B6-4788-8EE9-015C14D84DDD.png"></a></p><p>我们可以使用select…insert + 动态分区解决问题</p><h3 id="步骤"><a class="markdownIt-Anchor" href="#步骤"></a> 步骤</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode=nonstrict;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_1(datestr <span class="keyword">string</span>,u_id <span class="keyword">string</span>,acc_cnt <span class="built_in">bigint</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> t_1 <span class="keyword">values</span>(<span class="string">'2019-07-17'</span>,<span class="string">'1'</span>,<span class="number">22</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> t_1 <span class="keyword">values</span>(<span class="string">'2019-07-17'</span>,<span class="string">'2'</span>,<span class="number">24</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> t_1 <span class="keyword">values</span>(<span class="string">'2019-07-16'</span>,<span class="string">'3'</span>,<span class="number">255</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> t_2 <span class="keyword">partition</span> (datestr)</span><br><span class="line"><span class="keyword">select</span> u_id,acc_cnt,datestr <span class="keyword">from</span> t_1 <span class="keyword">where</span> datestr = <span class="string">'2019-07-17'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> t_2 <span class="keyword">partition</span> (datestr)</span><br><span class="line"><span class="keyword">select</span> u_id,acc_cnt,datestr <span class="keyword">from</span> t_1 <span class="keyword">where</span> datestr = <span class="string">'2019-07-16'</span>;</span><br></pre></td></tr></table></figure><p>加上下面这句话，不带where直接自动匹配datestr</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.dynamici.partition=<span class="literal">true</span>;</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> t_2 <span class="keyword">partition</span> (datestr)</span><br><span class="line"><span class="keyword">select</span> u_id,acc_cnt,datestr <span class="keyword">from</span> t_1;</span><br></pre></td></tr></table></figure><p>之后删掉t_1 修改t_2为t_1就行了</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;现在有个hive表 dw_revisit_user_d ，创建的时候没有加partitioned by,现在想
      
    
    </summary>
    
      <category term="大数据" scheme="yihao.ml/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="hive" scheme="yihao.ml/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>ceph集群搭建</title>
    <link href="yihao.ml/2019/07/17/2019-07-17-ceph/"/>
    <id>yihao.ml/2019/07/17/2019-07-17-ceph/</id>
    <published>2019-07-17T17:43:17.000Z</published>
    <updated>2019-11-29T12:20:47.704Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>作者林文杰；结构图如下图所示</p><p><a href="https://i.loli.net/2019/07/17/5d2eedf4bfdf563876.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2019/07/17/5d2eedf4bfdf563876.png" alt="ceph.png"></a></p><h3 id="1-selinux-防火墙和hostname文件"><a class="markdownIt-Anchor" href="#1-selinux-防火墙和hostname文件"></a> 1、Selinux、防火墙和hostname文件</h3><p>将/etc/selinux/config文件下SELINUX=disabled</p><p>关闭防火墙或者开通6789和6800：7300的端口</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hostname</span><br></pre></td></tr></table></figure><h3 id="2-配置用户"><a class="markdownIt-Anchor" href="#2-配置用户"></a> 2、配置用户</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">useradd -m bdipceph</span><br><span class="line">passwd bdipceph</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">设置su权限</span></span><br><span class="line">echo "bdipceph ALL = (root) NOPASSWD:ALL" | tee /etc/sudoers.d/bdipceph</span><br><span class="line">chmod 0440 /etc/sudoers.d/bdipceph</span><br></pre></td></tr></table></figure><h3 id="3-将各节点写入hosts"><a class="markdownIt-Anchor" href="#3-将各节点写入hosts"></a> 3、将各节点写入hosts</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo 192.168.140.130 ceph130 &gt;&gt; /etc/hosts</span><br><span class="line">echo 192.168.140.133 ceph133 &gt;&gt; /etc/hosts</span><br><span class="line">echo 192.168.140.134 ceph134 &gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure><h3 id="4-配置免密"><a class="markdownIt-Anchor" href="#4-配置免密"></a> 4、配置免密</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">su bdipceph</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line">ssh-copy-id ceph130</span><br><span class="line">ssh-copy-id ceph133</span><br><span class="line">ssh-copy-id ceph134</span><br></pre></td></tr></table></figure><h3 id="5-安装ntp服务和配置yum仓库"><a class="markdownIt-Anchor" href="#5-安装ntp服务和配置yum仓库"></a> 5、安装ntp服务和配置yum仓库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/yum.repo.d/CentOS-ceph.repo</span><br></pre></td></tr></table></figure><p>下面做参考</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">[Ceph]</span></span><br><span class="line"><span class="attr">name</span>=<span class="string">Ceph packages for $basearch</span></span><br><span class="line"><span class="attr">baseurl</span>=<span class="string">https://mirrors.aliyun.com/ceph/rpm-jewel/el7/$basearch</span></span><br><span class="line"><span class="attr">enabled</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">gpgcheck</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">type</span>=<span class="string">rpm-md</span></span><br><span class="line"><span class="attr">gpgkey</span>=<span class="string">https://mirrors.aliyun.com/ceph/keys/release.asc</span></span><br><span class="line"><span class="attr">priority</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">[Ceph-noarch]</span></span><br><span class="line"><span class="attr">name</span>=<span class="string">Ceph noarch packages</span></span><br><span class="line"><span class="attr">baseurl</span>=<span class="string">https://mirrors.aliyun.com/ceph/rpm-jewel/el7/noarch</span></span><br><span class="line"><span class="attr">enabled</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">gpgcheck</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">type</span>=<span class="string">rpm-md</span></span><br><span class="line"><span class="attr">gpgkey</span>=<span class="string">https://mirrors.aliyun.com/ceph/keys/release.asc</span></span><br><span class="line"><span class="attr">priority</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">[ceph-source]</span></span><br><span class="line"><span class="attr">name</span>=<span class="string">Ceph source packages</span></span><br><span class="line"><span class="attr">baseurl</span>=<span class="string">https://mirrors.aliyun.com/ceph/rpm-jewel/el7/SRPMS</span></span><br><span class="line"><span class="attr">enabled</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">gpgcheck</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">type</span>=<span class="string">rpm-md</span></span><br><span class="line"><span class="attr">gpgkey</span>=<span class="string">https://mirrors.aliyun.com/ceph/keys/release.asc</span></span><br></pre></td></tr></table></figure><h3 id="6-安装存储集群"><a class="markdownIt-Anchor" href="#6-安装存储集群"></a> 6、安装存储集群</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">yum install ceph-deploy</span><br><span class="line">su cephd</span><br><span class="line">mkdir ~/my-cluster</span><br><span class="line">ceph-deploy new ceph133</span><br><span class="line">osd pool default size = 2</span><br><span class="line">ceph-deploy install ceph130 ceph133 ceph134</span><br><span class="line">ceph-deploy mon create-initial</span><br><span class="line">ceph-deploy osd prepare ceph133:/var/local/osd0 ceph134:/var/local/osd1</span><br><span class="line">ceph-deploy osd activate ceph133:/var/local/osd0 ceph134:/var/local/osd1</span><br><span class="line">ceph-deploy admin ceph130 ceph133 ceph134</span><br><span class="line">chmod +r /etc/ceph/ceph.client.admin.keyring</span><br><span class="line">ceph health</span><br></pre></td></tr></table></figure><h3 id="7-删除osd"><a class="markdownIt-Anchor" href="#7-删除osd"></a> 7、删除osd</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ceph osd out 1</span><br><span class="line">systemctl stop ceph-osd@1</span><br><span class="line">ceph osd crush remove osd.1</span><br><span class="line">ceph auth del osd.1</span><br><span class="line">ceph osd rm osd.1</span><br><span class="line"><span class="meta">#</span><span class="bash">删除旧文件夹</span></span><br><span class="line">rm -rf /var/local/osd1</span><br><span class="line"><span class="meta">#</span><span class="bash">调整权重</span></span><br><span class="line">ceph osd crush reweight osd.1 0</span><br></pre></td></tr></table></figure><h3 id="8-配置文件修改发送"><a class="markdownIt-Anchor" href="#8-配置文件修改发送"></a> 8、配置文件修改发送</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy --overwrite-conf config push bdipceph104 bdipceph106 bdipceph108</span><br></pre></td></tr></table></figure><h3 id="9-配置文件内容"><a class="markdownIt-Anchor" href="#9-配置文件内容"></a> 9、配置文件内容</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">设置日志文件大小</span></span><br><span class="line">osd journal size = 1024</span><br><span class="line"><span class="meta">#</span><span class="bash">设置节点数量</span></span><br><span class="line">osd pool default size = 3</span><br><span class="line"><span class="meta">#</span><span class="bash">设置副本数量</span></span><br><span class="line">osd pool default min size = 2</span><br><span class="line"><span class="meta">#</span><span class="bash">设置ext4能够使用</span></span><br><span class="line">osd max object name len = 256</span><br><span class="line">osd max object namespace len = 64</span><br></pre></td></tr></table></figure><h3 id="10-创建块设备"><a class="markdownIt-Anchor" href="#10-创建块设备"></a> 10、创建块设备</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">创建映像foo大小4G</span></span><br><span class="line">rbd create --size 4096 foo</span><br><span class="line"><span class="meta">#</span><span class="bash">查询映像</span></span><br><span class="line">rbd ls</span><br><span class="line"><span class="meta">#</span><span class="bash">查询单个映像信息</span></span><br><span class="line">rbd info foo</span><br><span class="line"><span class="meta">#</span><span class="bash">扩大映像大小</span></span><br><span class="line">rbd resize --size 8192 foo</span><br><span class="line">resize2fs /dev/rbd0</span><br><span class="line"><span class="meta">#</span><span class="bash">减小映像大小(会损坏数据)</span></span><br><span class="line">rbd resize --size 4096 foo --allow-shrink</span><br><span class="line"><span class="meta">#</span><span class="bash">删除映像</span></span><br><span class="line">rbd rm foo</span><br><span class="line"><span class="meta">#</span><span class="bash">linux环境需要执行下面这条命令</span></span><br><span class="line">rbd feature disable foo exclusive-lock object-map fast-diff deep-flatten</span><br><span class="line"><span class="meta">#</span><span class="bash">映射块设备</span></span><br><span class="line">rbd map foo --name client.admin </span><br><span class="line"><span class="meta">#</span><span class="bash">查看已映射块设备</span></span><br><span class="line">rbd showmapped</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">取消块设备映射</span></span><br><span class="line">rbd unmap /dev/rbd0</span><br><span class="line">mkfs.ext4 /dev/rbd0</span><br></pre></td></tr></table></figure><h3 id="11-创建块设备快照"><a class="markdownIt-Anchor" href="#11-创建块设备快照"></a> 11、创建块设备快照</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">创建快照</span></span><br><span class="line">rbd snap create rbd/foo@snapfoo</span><br><span class="line"><span class="meta">#</span><span class="bash">罗列快照</span></span><br><span class="line">rbd snap ls rbd/foo</span><br><span class="line"><span class="meta">#</span><span class="bash">回滚快照</span></span><br><span class="line">rbd snap rollback rbd/foo@snapfoo</span><br><span class="line"><span class="meta">#</span><span class="bash">删除快照</span></span><br><span class="line">rbd snap rm rbd/foo@snapfoo</span><br><span class="line"><span class="meta">#</span><span class="bash">清除快照</span></span><br><span class="line">rbd snap purge rbd/foo</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;作者林文杰；结构图如下图所示&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://i.loli.net/2019/0
      
    
    </summary>
    
      <category term="大数据" scheme="yihao.ml/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="ceph" scheme="yihao.ml/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title>Export requires a --table or a --call argument</title>
    <link href="yihao.ml/2019/07/16/2019%E2%80%9307-16-Export-requires-a--table-or-a--call-argument/"/>
    <id>yihao.ml/2019/07/16/2019–07-16-Export-requires-a--table-or-a--call-argument/</id>
    <published>2019-07-16T11:03:59.000Z</published>
    <updated>2019-11-29T12:20:47.704Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>参考官方文档<a href="http://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html#_failed_exports" target="_blank" rel="noopener">10. sqoop-export</a>使用Sqoop导入数据到RDSMS数据库，结果报错；错误也是让人摸不着头脑，命令中是有这些参数的。</p><p><a href="https://i.loli.net/2019/07/16/5d2d42330c66764831.png" target="_blank" rel="noopener"><img src="https://i.loli.net/2019/07/16/5d2d42330c66764831.png" alt="1.png"></a></p><h3 id="解决办法"><a class="markdownIt-Anchor" href="#解决办法"></a> 解决办法</h3><p>做下面修改，在值的左右加上<font color="red">双引号</font>即可。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--connect "jdbc:sqlserver://ip:port;database=database" \</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;参考官方文档&lt;a href=&quot;http://sqoop.apache.org/docs/1.4.6/Sqoop
      
    
    </summary>
    
      <category term="其他" scheme="yihao.ml/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="问题总结" scheme="yihao.ml/tags/%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>分布式幂等性设计</title>
    <link href="yihao.ml/2019/07/15/2019%E2%80%9307-15-%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%82%E7%AD%89%E6%80%A7%E8%AE%BE%E8%AE%A1/"/>
    <id>yihao.ml/2019/07/15/2019–07-15-分布式幂等性设计/</id>
    <published>2019-07-15T20:57:00.000Z</published>
    <updated>2019-11-29T12:20:47.704Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><h3 id="幂等性"><a class="markdownIt-Anchor" href="#幂等性"></a> 幂等性</h3><p>幂等性指的是，请求一次或者是多次资源应该具有相同的副作用。</p><h3 id="重要性"><a class="markdownIt-Anchor" href="#重要性"></a> 重要性</h3><p>在一些业务场景下，幂等性显得很重要；比如金融系统、电商系统，这些都是很敏感的系统，作为软件开发者，我们有必要了解一下它。</p><ul><li>订单创建接口，第一次调用超时了，如果再调用一次会不会再创建一个订单？</li><li>购买商品时，减库存接口超时了，再调一次会不会扣减2个库存？</li><li>当一笔订单开始支付，支付请求发出后，服务端发生了扣钱操作，接口响应超时了，调用方再重试一次，会不会多扣一笔钱？</li></ul><p>下面我们介绍一下怎么解决上面所述的问题。</p><h3 id="设计"><a class="markdownIt-Anchor" href="#设计"></a> 设计</h3><p>通常我们有两个方法来保证幂等性。也就是不管调用接口多少次，都要产生相同的副作用：</p><ul><li>下游做一个查询接口，上游系统发现请求超时后，调用查询接口。发现成功了，逻辑里面什么都不用做；如果发现失败了，走失败流程进行后续处理保证最终结果正确。</li><li>把这个查询操作交给下游系统，上游系统只负责重试，下游系统要在代码上保证一次或多次请求结果是一样的.</li></ul><p>第一种没什么好说的，很好实现；第二种则需要利用一个全局ID来辅助完成。由于我们的系统是一个分布式的，要做到全局唯一貌有点小难度，分布式中，子系统很多。该由谁来维护这个全局ID？这里介绍一下Twitter 的开源项目Snowflake。它是一个分布式ID的生成算法，可以帮我们完成这个工作，你可以通过阅读下面这个文章来交接它https://www.cnblogs.com/haoxinyue/p/5208136.html</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;h3 id=&quot;幂等性&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#幂等性&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
      <category term="分布式" scheme="yihao.ml/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
  </entry>
  
  <entry>
    <title>希尔、归并、堆、快速排序</title>
    <link href="yihao.ml/2019/07/08/2019%E2%80%9307-03-%E5%B8%8C%E5%B0%94%E3%80%81%E5%BD%92%E5%B9%B6%E3%80%81%E5%A0%86%E3%80%81%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"/>
    <id>yihao.ml/2019/07/08/2019–07-03-希尔、归并、堆、快速排序/</id>
    <published>2019-07-08T19:34:38.000Z</published>
    <updated>2019-11-29T12:20:47.702Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>下面我们介绍一下时间复杂度为O（nlogn）的时间复杂度:<font color="red">希尔排序、归并排序、堆排序、快速排序</font></p><h3 id="堆排序"><a class="markdownIt-Anchor" href="#堆排序"></a> 堆排序</h3><ol><li><p>将0～（n-1）的无序列表，映射为大根堆，根据大根堆的特性，堆顶为最大值;</p></li><li><p>将堆顶与堆的最后一个元素交换位置，并将其脱离堆结构，放在数组n-1位置上;</p></li><li><p>重新调整大根堆，重复步骤2，得到第n-2的数</p></li><li><p>直到堆元素个数为1，即整个堆排序完成。</p></li></ol><p>图解流程访问下面链接中的 <a href="https://www.cs.usfca.edu/~galles/visualization/HeapSort.html" target="_blank" rel="noopener">Data Structure Visualizations</a></p><h3 id="希尔排序"><a class="markdownIt-Anchor" href="#希尔排序"></a> 希尔排序</h3><p>希尔排序是插入排序的进化版，插入排序的每次迁移步长为1,而希尔排序则通过动态调整步长，进而提高排序效率。假如选定步长为3下面说一下排序过程</p><ol><li><p>在0～（N-1）的无序序列中，数组中位置0、1、2三个数将被直接跳过。取3位置的数（a）和0位置上的数（b）比较。如果b&gt;a,则结束比较;如果b&lt;a,则交换b和a的位置，继续使用b和-3位置上的数比较，发现-3数组越界，结束比较;</p></li><li><p>取位置4上的数和位置1上的数比较，重复上面过程;</p></li><li><p>一直到最后一个位置n与n-3比较后结束步长为3的排序过程;</p></li><li><p>让步长减1继续完成上面1、2、3的步骤，知道步长=0,结束整个希尔排序过程;</p></li></ol><p>图解流程访问下面链接中的Shell Sort <a href="https://www.cs.usfca.edu/~galles/visualization/ComparisonSort.html" target="_blank" rel="noopener">Data Structure Visualizations</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 希尔排序其实是插入排序的一种优化</span></span><br><span class="line">    <span class="keyword">int</span> len = a.length;</span><br><span class="line">    <span class="keyword">int</span> w = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 自定义w的规则</span></span><br><span class="line">    <span class="keyword">while</span>(w &lt; len / <span class="number">3</span>) &#123;</span><br><span class="line">        w = <span class="number">3</span>*w + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//开始进行排序</span></span><br><span class="line">    <span class="keyword">while</span>(w &gt;= <span class="number">1</span>)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = w ; i &lt; len ; i ++)&#123;</span><br><span class="line">            <span class="comment">// 将a[i]插入到a[i-w]、a[i-2*w]、a[i-3*w]....</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = i ; j &gt;= w &amp;&amp; less(a[j],a[j-w]) ; j -=w )&#123;</span><br><span class="line">                exch(a,j,j-w);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        w = w / <span class="number">3</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="归并排序"><a class="markdownIt-Anchor" href="#归并排序"></a> 归并排序</h3><ol><li><p>在0～（n-1）的无序列表中，将大小为1的有序区间，合并为大小为2的有序区间;</p></li><li><p>将大小为2的有序区间合并为大小为4的有序区间;</p></li><li><p>直到有序区间大小容纳所有的数，归并排序完成;</p></li></ol><p>图解流程访问下面链接中的Merge Sort <a href="https://www.cs.usfca.edu/~galles/visualization/ComparisonSort.html" target="_blank" rel="noopener">Data Structure Visualizations</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Comparable[] aux;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span> </span>&#123;</span><br><span class="line">    aux = <span class="keyword">new</span> Comparable[a.length];</span><br><span class="line">    sort(a,<span class="number">0</span>,a.length-<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自上而下的归并排序</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a,<span class="keyword">int</span> lo,<span class="keyword">int</span> hi)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(hi &lt;= lo) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// a[lo...mid] 和 a[mid+1....hi]</span></span><br><span class="line">    <span class="keyword">int</span> mid = lo + (hi - lo)/<span class="number">2</span>;</span><br><span class="line">    sort(a,lo,mid);</span><br><span class="line">    sort(a,mid+<span class="number">1</span>,hi);</span><br><span class="line">    merge(a,lo,mid,hi);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 合并 a[lo...mid] 和 a[mid+1....hi]</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(Comparable[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> mid, <span class="keyword">int</span> hi)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化两个指针</span></span><br><span class="line">    <span class="keyword">int</span> i = lo;</span><br><span class="line">    <span class="keyword">int</span> j = mid + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将a复制到辅助数组aux</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> k = lo; k &lt;= hi; k++) &#123;</span><br><span class="line">        aux[k] = a[k];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 开始拿两个指针对应的数进行比较</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> k = lo; k &lt;= hi; k++) &#123;</span><br><span class="line">        <span class="comment">// j对应的数 比i小，将比较小的放在第k位置</span></span><br><span class="line">        <span class="keyword">if</span>(j &gt; hi)&#123;</span><br><span class="line">            a[k] = aux[i++];</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(i &gt; mid)&#123;<span class="comment">// 如果左边用完了，直接将右序列中的数放在k位置</span></span><br><span class="line">            a[k] = aux[j++];</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(less(aux[j],aux[i]))&#123; <span class="comment">// 如果右边用完了，直接将左序列中的数放在k位置</span></span><br><span class="line">            a[k] = aux[j++];</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            a[k] = aux[i++];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="快速排序"><a class="markdownIt-Anchor" href="#快速排序"></a> 快速排序</h3><p>利用分治的思想，要对大小为N的无序序列排序，将其分为a[lo]-a[j-1],a[j],a[j+1]-a[hi]三部分，保证a[lo]-a[j-1]中的数永远小于等于a[j];a[j+1]-a[hi]中的数永远大于a[j];</p><p>在分别递归的对a[lo]-a[j-1]和a[j+1]-a[hi]重复上面的步骤。</p><p>下面我们说一下什么叫划分过程，划分过程就是怎么将小于等于a[j]的数放到a[j]的左边，大于a[j]的数放在了a[j]的右边：</p><ol><li><p>选择一个数a[lo]，初始化左指针 i = lo ，右指针 j = hi；</p></li><li><p>i指针往右移，找到大于等于a[lo]的数(a);j指针往左移，找到小于a[lo]的数b。交换a和b的位置,然后i继续往右移，j继续往左移，直到两者交汇。</p></li><li><p>将a[lo]与a[j]交换位置</p></li></ol><p>图解流程访问下面链接中的Quick Sort <a href="https://www.cs.usfca.edu/~galles/visualization/ComparisonSort.html" target="_blank" rel="noopener">Data Structure Visualizations</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span> </span>&#123;</span><br><span class="line">    sort(a,<span class="number">0</span>,a.length-<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 快速排序</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a,<span class="keyword">int</span> lo ,<span class="keyword">int</span> hi)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(hi &lt;= lo) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 找到j,分别对a[lo..j-1]和a[j+1...hi]进行递归快速的排序</span></span><br><span class="line">    <span class="keyword">int</span> j = partition(a,lo,hi);</span><br><span class="line">    <span class="comment">// sort左序列\ sort右序列</span></span><br><span class="line">    sort(a,lo,j-<span class="number">1</span>);</span><br><span class="line">    sort(a,j+<span class="number">1</span>,hi);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对a[lo...hi] 进行划分排序</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(Comparable[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 定义两个指针</span></span><br><span class="line">    <span class="keyword">int</span> i = lo;</span><br><span class="line">    <span class="keyword">int</span> j = hi + <span class="number">1</span>;</span><br><span class="line">    Comparable v = a[lo];</span><br><span class="line">    <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">        <span class="comment">// 从左边往右边一直找到第一个比v大的数</span></span><br><span class="line">        <span class="keyword">while</span>(less(a[++i],v))<span class="keyword">if</span>(i == hi)<span class="keyword">break</span>;</span><br><span class="line">        <span class="comment">// 从右边往左边一直找到第一个比v小的数</span></span><br><span class="line">        <span class="keyword">while</span>(less(v,a[--j]) )<span class="keyword">if</span>(j == lo)<span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">if</span>(i &gt;= j) <span class="keyword">break</span>;</span><br><span class="line">        exch(a,i,j);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 比较完成后将j和lo位置上的数互换</span></span><br><span class="line">    exch(a,lo,j);</span><br><span class="line">    <span class="keyword">return</span> j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;下面我们介绍一下时间复杂度为O（nlogn）的时间复杂度:&lt;font color=&quot;red&quot;&gt;希尔排序、归并排
      
    
    </summary>
    
      <category term="算法与数据结构" scheme="yihao.ml/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>排序空间复杂度与稳定性</title>
    <link href="yihao.ml/2019/07/08/2019%E2%80%9307-08-%E6%8E%92%E5%BA%8F%E7%A9%BA%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E4%B8%8E%E7%A8%B3%E5%AE%9A%E6%80%A7/"/>
    <id>yihao.ml/2019/07/08/2019–07-08-排序空间复杂度与稳定性/</id>
    <published>2019-07-08T19:34:38.000Z</published>
    <updated>2019-11-29T12:20:47.703Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>8种经典排序算法已经整理完成，下面说一下他们的空间复杂度</p><h3 id="o1"><a class="markdownIt-Anchor" href="#o1"></a> O（1）</h3><p>插入排序、冒泡排序、选择排序、希尔排序、堆排序</p><h3 id="on~ologn"><a class="markdownIt-Anchor" href="#on~ologn"></a> O（n）～O（logn）</h3><p>快速排序</p><h3 id="on"><a class="markdownIt-Anchor" href="#on"></a> O（N）</h3><p>归并排序</p><blockquote><p>这里有一些网上和书上说可以将归并排序的空间复杂度优化到O（1），这边通过手摇算法确实可以使得空间复杂度达到O（1），但是时间复杂度会上升。</p></blockquote><h3 id="om"><a class="markdownIt-Anchor" href="#om"></a> O（M）</h3><p>计数排序、基数排序</p><blockquote><p>这个M代表的是桶的数量</p></blockquote><h3 id="稳定性"><a class="markdownIt-Anchor" href="#稳定性"></a> 稳定性</h3><p>所谓不稳定性，指的是相同元素经过排序后，改变了原数组中数的位置，即为不稳定的排序算法。</p><p>8种排序算法中，有选择排序、快速排序、希尔排序和堆排序他们是不稳定的排序算法</p><p>那么我们下面说一下，对于序列（5,5,5,1），为什么他们会是不稳定的排序算法</p><h4 id="选择排序"><a class="markdownIt-Anchor" href="#选择排序"></a> 选择排序</h4><p>选择排序，会将1与第一个5进行交换位置，导致相同元素排序后位置改变。</p><h4 id="快速排序"><a class="markdownIt-Anchor" href="#快速排序"></a> 快速排序</h4><p>对于快排而言，开始任意选择一个数，假如选到了第二个5,那么小于等于它的都将会被放到第二个5的左边，导致相同元素排序后位置改变。</p><h4 id="希尔排序"><a class="markdownIt-Anchor" href="#希尔排序"></a> 希尔排序</h4><p>假如希尔排序的步长选为2,在1和第二个5比较以后，会和它交换位置，导致相同元素排序后位置改变。</p><h4 id="堆排序"><a class="markdownIt-Anchor" href="#堆排序"></a> 堆排序</h4><p>将上面元素映射为大根堆，堆顶元素会和最后一个元素交换位置，导致相同元素排序后位置改变。</p><h3 id="小结"><a class="markdownIt-Anchor" href="#小结"></a> 小结</h3><ol><li><p>在解决工程问题时，通常会使用多个排序算法相结合的套路，来解决问题。面对问题时要活学活用，比如使用计数排序解决按身高排序的问题很高效，但是放在解决按工资排序的问题上就不是那么好了。</p></li><li><p>一般，对于数量不大的情况下，通常选取时间复杂度为O（n^2）的插入排序算法</p></li><li><p>对于数量很大的情况下，通常选取快速排序，或者是其他的时间复杂度为O（nlogn）的排序算法</p></li></ol><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;8种经典排序算法已经整理完成，下面说一下他们的空间复杂度&lt;/p&gt;&lt;h3 id=&quot;o1&quot;&gt;&lt;a class=&quot;m
      
    
    </summary>
    
      <category term="算法与数据结构" scheme="yihao.ml/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>计数和基数排序</title>
    <link href="yihao.ml/2019/07/08/2019%E2%80%9307-08-%E8%AE%A1%E6%95%B0%E5%92%8C%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F/"/>
    <id>yihao.ml/2019/07/08/2019–07-08-计数和基数排序/</id>
    <published>2019-07-08T19:34:38.000Z</published>
    <updated>2019-11-29T12:20:47.703Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>O（N）的排序算法也叫不比较的排序算法，它的思想源于桶排序，其中比较经典的两个例子<font color="red">计数排序和基数排序</font>，它们的时间复杂度趋向于O（n）</p><p>你可能会纳闷，不比较也能排序？下面我们介绍一下这两种经典排序算法</p><h3 id="计数排序"><a class="markdownIt-Anchor" href="#计数排序"></a> 计数排序</h3><p>假如要给公司员工按身高排序。</p><ol><li><p>我们知道员工身高大部分在160，180 之间，建立100～300一共200个桶。</p></li><li><p>遍历所有员工，按身高把员工放到匹配的桶中</p></li><li><p>分别倒出100～300号桶中的员工，这就是一个按身高排好序的序列。</p></li></ol><h3 id="基数排序"><a class="markdownIt-Anchor" href="#基数排序"></a> 基数排序</h3><p>给下面序列 （124，220，044，120，334，666，001，099）排序，其中都为10进制数；</p><ol><li><p>建立 0～9 共10个桶</p></li><li><p>根据上面数的个位，分别放到对应的桶中，比如124，个位是4，就放到4对应的桶中；</p></li><li><p>依次倒出所有数，再根据数的十位，分别放到对应的桶中；</p></li><li><p>依次倒出所有数，再根据数的百位，分别放到对应的桶中；</p></li><li><p>依次倒出所有的数，该序列就是从小到大的有序序列；</p></li></ol><p>下面这个网站中可以给你一些好的桶排序的思想，如果有时间，不妨看一下图解<br><a href="https://www.cs.usfca.edu/~galles/visualization/BucketSort.html" target="_blank" rel="noopener">Bucket Sort</a><br><a href="https://www.cs.usfca.edu/~galles/visualization/CountingSort.html" target="_blank" rel="noopener">Counting Sort</a><br><a href="https://www.cs.usfca.edu/~galles/visualization/RadixSort.html" target="_blank" rel="noopener">Radix Sort</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;O（N）的排序算法也叫不比较的排序算法，它的思想源于桶排序，其中比较经典的两个例子&lt;font color=&quot;r
      
    
    </summary>
    
      <category term="算法与数据结构" scheme="yihao.ml/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>冒泡、插入、选择排序</title>
    <link href="yihao.ml/2019/07/03/2019-07-03-%E5%86%92%E6%B3%A1%E3%80%81%E6%8F%92%E5%85%A5%E3%80%81%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/"/>
    <id>yihao.ml/2019/07/03/2019-07-03-冒泡、插入、选择排序/</id>
    <published>2019-07-03T20:54:38.000Z</published>
    <updated>2019-11-29T12:20:47.702Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>下面我们来理一下时间复杂度为O（n^2）的排序算法：<font color="red">冒泡排序、插入排序和选择排序</font></p><h3 id="冒泡排序"><a class="markdownIt-Anchor" href="#冒泡排序"></a> 冒泡排序</h3><ol><li><p>在0～（N-1）的大小区间中，数组位置0和数组位置1上的进行比较，如果0位置上的大于1位置上的，交换他们的位置，否则不动；紧接着位置1上的和位置2上的进行比较，如果1位置上的大于2位置上的，交换他们的位置，如此反复第一轮下来，数组中最大的那个数会被放到数组的最后面。</p></li><li><p>将0～（N-1）的区间缩小为0～（N-2），反复上述过程。第二轮下来后，最大的会被放到倒数第二个位置。</p></li><li><p>以此类推完成后面各轮过程，直到数组区间大小为1，即整个过程结束。</p></li></ol><p>图解流程访问下面链接中的Bubble Sort <a href="https://www.cs.usfca.edu/~galles/visualization/ComparisonSort.html" target="_blank" rel="noopener">Data Structure Visualizations</a></p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">less</span><span class="params">(a <span class="keyword">int</span>, b <span class="keyword">int</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> a&lt;b</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">exch</span><span class="params">(a *<span class="keyword">int</span>, b *<span class="keyword">int</span>)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">temp := *a</span><br><span class="line">*a = *b</span><br><span class="line">*b = temp</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">bsort</span><span class="params">(a *[10]<span class="keyword">int</span>)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">count := <span class="built_in">len</span>(a)</span><br><span class="line"><span class="comment">//fmt.Println(count)</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; count; i++ &#123;</span><br><span class="line"><span class="keyword">for</span> j := i + <span class="number">1</span>; j &lt; count; j++ &#123;</span><br><span class="line"><span class="keyword">if</span> less(a[j], a[i]) &#123;</span><br><span class="line">exch(&amp;(*a)[j],&amp;(*a)[i])</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> a = [<span class="number">10</span>]<span class="keyword">int</span>&#123;<span class="number">3</span>,<span class="number">14</span>,<span class="number">2232</span>,<span class="number">4</span>,<span class="number">54</span>,<span class="number">62</span>,<span class="number">351</span>,<span class="number">422</span>,<span class="number">123</span>,<span class="number">34</span>&#125;</span><br><span class="line">fmt.Println(a)</span><br><span class="line"><span class="comment">//fmt.Println(count)</span></span><br><span class="line">bsort(&amp;a)</span><br><span class="line">fmt.Println(a)</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="插入排序"><a class="markdownIt-Anchor" href="#插入排序"></a> 插入排序</h3><ol><li><p>数组0位置（a）和数组1位置（b）上的数进行比较，如果后者b比前者a小，将b与a交换位置，紧接着b再和数组-1上的位置进行比较，发现数组越越界，结束第一轮的过程。</p></li><li><p>将待处理区间的大小缩小为1～（N-1），数组1位置上的数（a）与数组2位置上的数（b<br>）进行比较，同样的，如果后者b比前者a小，就将两个数进行交换，继续拿数组1位置上的数与数0位置上的数进行比较直到不满足后者小于前者，或者数组越界为止。结束第二轮的过程。</p></li><li><p>反复上面的过程直到待比较区间大小为1停止整个插入排序。</p></li></ol><p>图解流程访问下面链接中的Insertion Sort <a href="https://www.cs.usfca.edu/~galles/visualization/ComparisonSort.html" target="_blank" rel="noopener">Data Structure Visualizations</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> len = a.length;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i =<span class="number">0</span> ; i &lt; len ; i++)&#123;</span><br><span class="line">        <span class="comment">// 将a[i] 插入到 a[i - 1] , a[i - 2], a[ i - 3]</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = i ; j &gt;= <span class="number">1</span> &amp;&amp; less(a[j],a[j-<span class="number">1</span>]) ; j -= <span class="number">1</span>)&#123;</span><br><span class="line">            exch(a,j,j-<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="选择排序"><a class="markdownIt-Anchor" href="#选择排序"></a> 选择排序</h3><ol><li><p>在0～（N-1）的比较区间中，从头到尾依次比较找出最小的数，放在位置0上，将区间长度变为1～（N-1）</p></li><li><p>在1～（N-1）的比较区间中，从头到尾依次比较找出最小的数，放在位置1上，将区间长度变为2～（N-1）</p></li><li><p>反复上述过程知道比较区间大小为0，结束整个排序过程。</p></li></ol><p>图解流程访问下面链接中的Selection Sort <a href="https://www.cs.usfca.edu/~galles/visualization/ComparisonSort.html" target="_blank" rel="noopener">Data Structure Visualizations</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> len = a.length;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; len ; i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> min = i;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = i + <span class="number">1</span> ; j &lt; len  ; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>( less(a[j],a[min]) ) min = j;</span><br><span class="line">            &#125;</span><br><span class="line">            exch (a,i,min);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;下面我们来理一下时间复杂度为O（n^2）的排序算法：&lt;font color=&quot;red&quot;&gt;冒泡排序、插入排序和选
      
    
    </summary>
    
      <category term="算法与数据结构" scheme="yihao.ml/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
  <entry>
    <title>最好、最坏、平均 、均摊时间复杂度</title>
    <link href="yihao.ml/2019/07/03/2019-07-03-%E6%9C%80%E5%A5%BD%E3%80%81%E6%9C%80%E5%9D%8F%E3%80%81%E5%B9%B3%E5%9D%87%20%E3%80%81%E5%9D%87%E6%91%8A%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6/"/>
    <id>yihao.ml/2019/07/03/2019-07-03-最好、最坏、平均 、均摊时间复杂度/</id>
    <published>2019-07-03T20:42:05.000Z</published>
    <updated>2019-11-29T12:20:47.703Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --><p>较为复杂的分析方法大致可分为四类、分别为：<font color="red">最好时间复杂度、最坏时间复杂度、平均时间复杂度和均摊时间复杂度</font>。</p><p>这里有一段代码，针对它下面分别来说一下怎么算着四种时间复杂度。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// i的取值范围是 0～n</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> element)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (i &gt;= len) &#123;</span><br><span class="line">    <span class="keyword">int</span> new_array[] = <span class="keyword">new</span> <span class="keyword">int</span>[len*<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; len; ++j) &#123;</span><br><span class="line">      new_array[j] = array[j];</span><br><span class="line">    &#125;</span><br><span class="line">    array = new_array;</span><br><span class="line">    len = <span class="number">2</span> * len;</span><br><span class="line">  &#125;</span><br><span class="line">  array[i] = element;</span><br><span class="line">  ++i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="最好-最坏时间复杂度"><a class="markdownIt-Anchor" href="#最好-最坏时间复杂度"></a> 最好、最坏时间复杂度</h3><p>最好时间复杂度，言明直意，就是在最好情况下求得的时间复杂度，对于上面代码，针对长度为N的数组添加一个元素的最好时间复杂度为O（1）</p><p>在最好情况下，数组空间很充足，可以直接将数组添加到第i位置</p><p>在最坏情况下，数组空间不够，所以要重新申请一个2倍大小的数组空间，把原来array数组中的数据依次copy到new_array，因此最坏的时间复杂度应该是O（N）</p><h3 id="平均时间复杂度"><a class="markdownIt-Anchor" href="#平均时间复杂度"></a> 平均时间复杂度</h3><p>最好、坏的时间复杂度局限性很大，有时不能准确说明问题，针对这种情况，我们用代码执行各种情况的加权平均值来说明问题。</p><p>假设数组的大小为N，i的取值范围为0～N，在0～n-1时间复杂度为O（1），在i等于N的时候时间复杂度为O（N），i的取值有1/（n-1）种可能性，所以有：</p><p><a href="https://i.loli.net/2019/07/03/5d1c9ddc07f6c71312.jpeg" target="_blank" rel="noopener"><img src="https://i.loli.net/2019/07/03/5d1c9ddc07f6c71312.jpeg" alt="06D6CABC-665D-422E-B3A6-CB2C6F1076C9.jpeg"></a></p><p>最终平均时间复杂度是O（1）</p><h3 id="均摊时间复杂度"><a class="markdownIt-Anchor" href="#均摊时间复杂度"></a> 均摊时间复杂度</h3><p>网上有好多说平均时间复杂度就是均摊时间复杂度，它们并没有什么区别，不管他们俩是否一样，这边有两个tip来帮助我们算出均摊时间复杂度</p><ol><li>在N种情况中，如果第被低阶复杂度占去了半壁江山，那么通过均摊更高阶的复杂度到低阶上，最终结果为低阶复杂度。</li><li>假如你发现低阶复杂度和高阶复杂度出现规律性的交替，那么通常最终结果为低阶复杂度。</li></ol><p>根据上面的tips。很快就得出它的均摊时间复杂度为O（1）</p><h3 id="为什么要引入这4种复杂度"><a class="markdownIt-Anchor" href="#为什么要引入这4种复杂度"></a> 为什么要引入这4种复杂度？</h3><p>一般我们用不到到这些分析方法，针对某些场景，如果普通的分析方法不能论证我们的论点，那么使用它们往往可以使论点更具有说服力。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Nov 29 2019 12:20:56 GMT+0000 (Coordinated Universal Time) --&gt;&lt;p&gt;较为复杂的分析方法大致可分为四类、分别为：&lt;font color=&quot;red&quot;&gt;最好时间复杂度、最坏时间复杂度、
      
    
    </summary>
    
      <category term="算法与数据结构" scheme="yihao.ml/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
  </entry>
  
</feed>
